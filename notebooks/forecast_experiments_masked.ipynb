{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56aac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "from src.preprocess.preprocess import load_data, split_last\n",
    "from src.plot.altair import plot_total, plot_estimate\n",
    "from src.plot.formatting import dummy_forecast\n",
    "from src.utils.preprocess import MinMaxScaler, downcast\n",
    "from src.model.model import det_dot, drift_model, seasonality_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxid = [\n",
    "    \"ESD.000088-1\",\n",
    "    \"063.623-1\",\n",
    "    \"VRY.CHOPS-1\",\n",
    "    \"HVT.111153-1\",\n",
    "    \"TTR.251049-1\",\n",
    "    \"BGL.CROLA-1\",\n",
    "][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a4af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data, df_meta = load_data(boxid=boxid)\n",
    "# extreme = \"max\"\n",
    "# df_data = df_data.query(f\"extreme == '{extreme}'\")\n",
    "df_train, df_test = split_last(df_data.copy())\n",
    "df_test[\"period\"] = \"future\"\n",
    "plot_total(df_data=df_train, df_meta=df_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3309c",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrapolate_data(df, horizon=dt.timedelta(weeks=26)):\n",
    "    t_start = df[\"date\"].max() + dt.timedelta(weeks=1)\n",
    "    t_end = t_start + horizon + dt.timedelta(weeks=1)\n",
    "    t_extra = np.arange(t_start, t_end, dt.timedelta(weeks=1))\n",
    "    df_extra = pd.DataFrame(data=t_extra, columns=[\"date\"]).assign(\n",
    "        boxid=df[\"boxid\"].iloc[0], l=df[\"l\"].iloc[0], extreme=df[\"extreme\"].iloc[0], period=\"future\"\n",
    "    )\n",
    "    df_extra[[\"year\", \"week\"]] = df_extra[\"date\"].dt.isocalendar().iloc[:, :-1]\n",
    "\n",
    "    return df_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b278643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(t, y, p_fourier, n_fourier=5, n_polynomial=2):\n",
    "    \n",
    "    with pm.Model() as m:\n",
    "    \n",
    "        drift = drift_model(t, n=2)\n",
    "        yearly = seasonality_model(t, p=p_fourier)\n",
    "\n",
    "        σ_ε = pm.Uniform('σ_ε', lower=0, upper=1)\n",
    "        Σ = pm.Normal(\"Σ\", mu = drift + yearly, sd=σ_ε, observed=y)\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_quantile_bands(df_base, samples, quantiles=[5, 15, 50, 85, 95]):\n",
    "    # get quantiles\n",
    "    q_data = np.quantile(samples, [q / 100 for q in quantiles], axis=0)\n",
    "    boundaries = [\"upper\", \"lower\"]\n",
    "    df_bands = pd.DataFrame()\n",
    "\n",
    "    # create bands from two quantile boundaries (median: upper=lower)\n",
    "    for ci in range(math.ceil(len(quantiles) / 2)):\n",
    "        # name band\n",
    "        band_range = f\"Q{quantiles[ci]}-Q{quantiles[-ci-1]}\".replace(\n",
    "            \"Q50-Q50\", \"median\"\n",
    "        )\n",
    "\n",
    "        df_band = df_base.copy()\n",
    "        df_band[boundaries] = q_data[[-ci - 1, ci]].T\n",
    "        df_band[\"band\"] = band_range\n",
    "\n",
    "        # append to other bands\n",
    "        df_bands = pd.concat([df_bands, df_band], axis=0)\n",
    "\n",
    "    # in long format\n",
    "    df_bands = df_bands.melt(\n",
    "        id_vars=df_bands.columns.difference(boundaries),\n",
    "        value_vars=boundaries,\n",
    "        var_name=\"boundary\",\n",
    "        value_name=\"value\",\n",
    "    )\n",
    "\n",
    "    return df_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a976240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_estimates(df_base, pp):\n",
    "    df_vars = pd.DataFrame()\n",
    "    for var, samples in pp.items():\n",
    "        # get per model variable the quantile bands\n",
    "        df_var = make_quantile_bands(df_base, samples=samples).assign(model_var=var)\n",
    "        df_vars = pd.concat([df_vars, df_var], axis=0)\n",
    "\n",
    "    return df_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_estimates(df_observed):\n",
    "\n",
    "    # extend date\n",
    "    df_future = extrapolate_data(df_observed)\n",
    "    df_full_range = pd.concat([df_observed, df_future])\n",
    "\n",
    "    # scale t, y, p\n",
    "    t_scaler = MinMaxScaler(lower=0)\n",
    "    t = t_scaler.fit_transform(X=df_full_range[\"date\"])\n",
    "    y_scaler = MinMaxScaler(lower=0)\n",
    "    y_observed = y_scaler.fit_transform(X=df_full_range[\"value\"])\n",
    "    # y_observed = np.ma.masked_invalid(y_observed)\n",
    "    p = t_scaler.transform(t_scaler.min + dt.timedelta(weeks=52.1775))\n",
    "\n",
    "    # create model \n",
    "    m = create_model(t=t, y=y_observed, p_fourier=p)\n",
    "    # display(pm.model_to_graphviz(m))\n",
    "    # tune model\n",
    "    trace = pm.sample(model=m, draws=500, tune=500, init=\"adapt_diag\")\n",
    "    # extract posterior predictions\n",
    "    pp = pm.sample_posterior_predictive(model=m, trace=trace, samples=1000, var_names=[\"drift\", \"yearly\", \"Σ\"])\n",
    "\n",
    "    # inverse scale samples\n",
    "    for k in pp.keys():\n",
    "            pp[k] = y_scaler.inverse_transform(pp[k])\n",
    "            if k == \"yearly\":\n",
    "                pp[k] -= y_scaler.min  \n",
    "\n",
    "    # create base df and join it with posterior predictive quantiles\n",
    "    df_base=df_full_range.drop(columns=[\"value\", \"processed_on\", \"model_var\"]).copy()\n",
    "    df_estimates = format_model_estimates(df_base, pp)\n",
    "    \n",
    "    return df_estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c5fac",
   "metadata": {},
   "source": [
    "## forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_train, df_test], axis=0)\n",
    "for extreme in [\"min\", \"max\"]:\n",
    "    df_observed = df_train.query(f\"extreme == '{extreme}'\")\n",
    "    df_estimates = determine_estimates(df_observed)\n",
    "\n",
    "    df_total = pd.concat([df_total, df_estimates], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d091939",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_total(df_data=df_total.query(\"model_var=='observed' | (model_var=='Σ' & period=='future')\"), df_meta=df_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00157d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f5188",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_estimate(df_total.query(\"model_var=='drift'\"), legend=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8430608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decomp(df):\n",
    "    plot_vars = []\n",
    "    for var in [\"Σ\", \"drift\", \"yearly\"]:\n",
    "        plot_var = plot_estimate(\n",
    "            df.query(f\"model_var=='{var}'\"), legend=None\n",
    "        ).properties(\n",
    "            title=var,\n",
    "            height=100,\n",
    "        )\n",
    "        plot_vars.append(plot_var)\n",
    "    return alt.vconcat(*plot_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4493f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decomp(df_total.query(\"extreme == 'max'\"))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:spark] *",
   "language": "python",
   "name": "conda-env-spark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
