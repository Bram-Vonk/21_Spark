{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a849e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "from src.utils.parser import parse_config\n",
    "from src.utils.vault import get_secrets\n",
    "from src.utils.processing import downcast\n",
    "import snowflake.connector\n",
    "\n",
    "config = parse_config(os.path.abspath(os.path.join(os.getcwd(), \"../src/settings.yml\")))\n",
    "parquet_file = \"../data/raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b21ab3",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "data_config = get_secrets(\"snowflake\")\n",
    "data_config.update(config[\"snowflake\"][\"data\"])\n",
    "snowflake_ctx = snowflake.connector.connect(**data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "829ea96d",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "last_processed = \"2000-1-1 15:35:04.518 UTC\"\n",
    "# last_processed = pd.read_parquet(\"../data/raw\", columns=[\"processed_on\"]).max()[0]\n",
    "last_processed = dt.datetime.strptime(last_processed, \"%Y-%m-%d %H:%M:%S.%f %Z\").date()\n",
    "from_date = last_processed - dt.timedelta(days=last_processed.weekday())\n",
    "\n",
    "channel_like = \"register://electricity/0/activepower/%?avg=15\"\n",
    "# channel_like = \"register://electricity/0/activepower/l_?avg=15\"\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    t0.BOXID AS BOXID,\n",
    "    t0.CHANNELID AS CHANNELID,\n",
    "    YEAROFWEEKISO(t0.DATUMTIJD) AS YEAR,\n",
    "    WEEKISO(t0.DATUMTIJD) AS WEEK,\n",
    "    CURRENT_TIMESTAMP AS PROCESSED_ON,\n",
    "    MAX(t0.WAARDE) AS MAX_VALUE,\n",
    "    MIN(t0.WAARDE) AS MIN_VALUE\n",
    "FROM {data_config[\"database\"]}.{data_config[\"schema\"]}.{data_config[\"table\"]} t0\n",
    "    WHERE t0.CHANNELID LIKE '{channel_like}'\n",
    "     AND t0.DATUMTIJD >= DATE('{from_date}')\n",
    "     AND t0.DATUMTIJD < DATEADD(DAY, -DAYOFWEEKISO(CURRENT_DATE), CURRENT_DATE)\n",
    "     AND t0.BOXID IN ('075.547-1', '069.509-1')\n",
    "GROUP BY t0.BOXID, t0.CHANNELID, YEAROFWEEKISO(t0.DATUMTIJD), WEEKISO(t0.DATUMTIJD)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96da40c1",
   "metadata": {
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87 ms, sys: 128 ms, total: 215 ms\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_query = pd.read_sql(sql=query, con=snowflake_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d667179",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "pattern = channel_like\\\n",
    "    .replace(\"?\", \"\\?\")\\\n",
    "    .replace(\"/\", \"\\/\")\\\n",
    "    .replace(\"%\", \"(sumli|l[1,2,3])\")\n",
    "df_query[\"L\"] = df_query[\"CHANNELID\"].str.extract(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c082a3fc",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df_query = df_query.apply(downcast, try_numeric=True, category=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3c5053",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 588 entries, 0 to 587\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   BOXID         588 non-null    category           \n",
      " 1   CHANNELID     588 non-null    category           \n",
      " 2   YEAR          588 non-null    uint16             \n",
      " 3   WEEK          588 non-null    uint8              \n",
      " 4   PROCESSED_ON  588 non-null    datetime64[ns, UTC]\n",
      " 5   MAX_VALUE     588 non-null    float32            \n",
      " 6   MIN_VALUE     588 non-null    float32            \n",
      " 7   L             588 non-null    category           \n",
      "dtypes: category(3), datetime64[ns, UTC](1), float32(2), uint16(1), uint8(1)\n",
      "memory usage: 13.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_query.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b871ae",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df_query.to_parquet(parquet_file, partition_cols=[\"BOXID\", \"L\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a78905d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOXID</th>\n",
       "      <th>CHANNELID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>PROCESSED_ON</th>\n",
       "      <th>MAX_VALUE</th>\n",
       "      <th>MIN_VALUE</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>075.547-1</td>\n",
       "      <td>register://electricity/0/activepower/l2?avg=15</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-02 09:50:35.731000+00:00</td>\n",
       "      <td>55.125271</td>\n",
       "      <td>10.691280</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>075.547-1</td>\n",
       "      <td>register://electricity/0/activepower/l2?avg=15</td>\n",
       "      <td>2020</td>\n",
       "      <td>52</td>\n",
       "      <td>2021-09-02 09:50:35.731000+00:00</td>\n",
       "      <td>53.982140</td>\n",
       "      <td>13.882600</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>075.547-1</td>\n",
       "      <td>register://electricity/0/activepower/l2?avg=15</td>\n",
       "      <td>2020</td>\n",
       "      <td>20</td>\n",
       "      <td>2021-09-02 09:50:35.731000+00:00</td>\n",
       "      <td>38.883331</td>\n",
       "      <td>-5.431684</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>075.547-1</td>\n",
       "      <td>register://electricity/0/activepower/l2?avg=15</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>2021-09-02 09:50:35.731000+00:00</td>\n",
       "      <td>40.508598</td>\n",
       "      <td>-3.709962</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>075.547-1</td>\n",
       "      <td>register://electricity/0/activepower/l2?avg=15</td>\n",
       "      <td>2020</td>\n",
       "      <td>46</td>\n",
       "      <td>2021-09-02 09:50:35.731000+00:00</td>\n",
       "      <td>50.619869</td>\n",
       "      <td>1.707081</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>075.547-1</td>\n",
       "      <td>register://electricity/0/activepower/l3?avg=15</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-09-02 09:50:35.731000+00:00</td>\n",
       "      <td>44.156551</td>\n",
       "      <td>8.423216</td>\n",
       "      <td>l3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>069.509-1</td>\n",
       "      <td>register://electricity/0/activepower/l3?avg=15</td>\n",
       "      <td>2021</td>\n",
       "      <td>32</td>\n",
       "      <td>2021-09-02 09:50:35.731000+00:00</td>\n",
       "      <td>0.195667</td>\n",
       "      <td>-53.594250</td>\n",
       "      <td>l3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>069.509-1</td>\n",
       "      <td>register://electricity/0/activepower/sumli?avg=15</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-02 09:50:35.731000+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sumli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>069.509-1</td>\n",
       "      <td>register://electricity/0/activepower/l3?avg=15</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-02 09:50:35.731000+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>l3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>069.509-1</td>\n",
       "      <td>register://electricity/0/activepower/l2?avg=15</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-02 09:50:35.731000+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BOXID                                          CHANNELID  YEAR  WEEK  \\\n",
       "0    075.547-1     register://electricity/0/activepower/l2?avg=15  2021     1   \n",
       "1    075.547-1     register://electricity/0/activepower/l2?avg=15  2020    52   \n",
       "2    075.547-1     register://electricity/0/activepower/l2?avg=15  2020    20   \n",
       "3    075.547-1     register://electricity/0/activepower/l2?avg=15  2020    16   \n",
       "4    075.547-1     register://electricity/0/activepower/l2?avg=15  2020    46   \n",
       "..         ...                                                ...   ...   ...   \n",
       "583  075.547-1     register://electricity/0/activepower/l3?avg=15  2019     7   \n",
       "584  069.509-1     register://electricity/0/activepower/l3?avg=15  2021    32   \n",
       "585  069.509-1  register://electricity/0/activepower/sumli?avg=15  2021     2   \n",
       "586  069.509-1     register://electricity/0/activepower/l3?avg=15  2021     2   \n",
       "587  069.509-1     register://electricity/0/activepower/l2?avg=15  2021     2   \n",
       "\n",
       "                        PROCESSED_ON  MAX_VALUE  MIN_VALUE      L  \n",
       "0   2021-09-02 09:50:35.731000+00:00  55.125271  10.691280     l2  \n",
       "1   2021-09-02 09:50:35.731000+00:00  53.982140  13.882600     l2  \n",
       "2   2021-09-02 09:50:35.731000+00:00  38.883331  -5.431684     l2  \n",
       "3   2021-09-02 09:50:35.731000+00:00  40.508598  -3.709962     l2  \n",
       "4   2021-09-02 09:50:35.731000+00:00  50.619869   1.707081     l2  \n",
       "..                               ...        ...        ...    ...  \n",
       "583 2021-09-02 09:50:35.731000+00:00  44.156551   8.423216     l3  \n",
       "584 2021-09-02 09:50:35.731000+00:00   0.195667 -53.594250     l3  \n",
       "585 2021-09-02 09:50:35.731000+00:00   0.000000   0.000000  sumli  \n",
       "586 2021-09-02 09:50:35.731000+00:00   0.000000   0.000000     l3  \n",
       "587 2021-09-02 09:50:35.731000+00:00   0.000000   0.000000     l2  \n",
       "\n",
       "[588 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1319675d",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d912da71cb44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"BOXID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VALUE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"YEAR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"WEEK\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TOP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BOTTOM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m df_read = (\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparquet_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TOP == 1 & L == 'sumli'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TOP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BOTTOM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/spark/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[1;32m    316\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/spark/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_pandas_metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         result = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         ).to_pandas()\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/spark/lib/python3.8/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes)\u001b[0m\n\u001b[1;32m   1670\u001b[0m             )\n\u001b[1;32m   1671\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m             dataset = _ParquetDatasetV2(\n\u001b[0m\u001b[1;32m   1673\u001b[0m                 \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m                 \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/spark/lib/python3.8/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m                 infer_dictionary=True)\n\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m         self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n\u001b[0m\u001b[1;32m   1533\u001b[0m                                    \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparquet_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m                                    \u001b[0mpartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/spark/lib/python3.8/site-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;31m# TODO(kszucs): support InMemoryDataset for a table input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_filesystem_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/spark/lib/python3.8/site-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0mfactory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystemDatasetFactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cols = [\"BOXID\", \"VALUE\", \"YEAR\", \"WEEK\", \"TOP\", \"BOTTOM\", \"L\"]\n",
    "df_read = (\n",
    "    pd.read_parquet(parquet_file, columns=cols)\n",
    "    .query(\"TOP == 1 & L == 'sumli'\")\n",
    "    .drop(columns=[\"TOP\", \"BOTTOM\", \"L\"])\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd6fc9",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df_read.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd64e1",
   "metadata": {},
   "source": [
    "## get meta data about parquet for sake of speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbead15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2394e4e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-972a6d8acd5f>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-972a6d8acd5f>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    https://arrow.apache.org/docs/python/parquet.html?highlight=pyarrow%20parquet%20partition\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "metadata = pq.read_metadata(\"../data/raw/BOXID=001.622-1/L=l1/7c3663dfe57547cb8fc54c33857b6caf.parquet\")\n",
    "\n",
    "# parquet_file = pq.ParquetFile(\"../data/raw/BOXID=001.622-1/L=l1/7c3663dfe57547cb8fc54c33857b6caf.parquet\")\n",
    "# metadata = parquet_file.metadata\n",
    "# metadata.row_group(0).column(6)\n",
    "\n",
    "## see parquet engine for possibilities to read _COMMON_METEDATA\n",
    "https://arrow.apache.org/docs/python/parquet.html?highlight=pyarrow%20parquet%20partition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ed99b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:spark] *",
   "language": "python",
   "name": "conda-env-spark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
