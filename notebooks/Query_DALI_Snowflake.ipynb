{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a849e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "from src.utils.parser import parse_config\n",
    "from src.utils.vault import get_secrets\n",
    "from src.utils.processing import downcast\n",
    "import snowflake.connector\n",
    "\n",
    "config = parse_config(os.path.abspath(os.path.join(os.getcwd(), \"../src/settings.yml\")))\n",
    "parquet_file = \"../data/raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b21ab3",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "data_config = get_secrets(\"snowflake\")\n",
    "data_config.update(config[\"snowflake\"][\"data\"])\n",
    "snowflake_ctx = snowflake.connector.connect(**data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ea96d",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "n_extremes = 5\n",
    "\n",
    "last_processed = \"2000-1-1 15:35:04.518 UTC\"\n",
    "# last_processed = pd.read_parquet(\"../data/raw\", columns=[\"processed_on\"]).max()[0]\n",
    "last_processed = dt.datetime.strptime(last_processed, \"%Y-%m-%d %H:%M:%S.%f %Z\").date()\n",
    "from_date = last_processed - dt.timedelta(days=last_processed.weekday())\n",
    "\n",
    "channel_like = \"register://electricity/0/activepower/%?avg=15\"\n",
    "# channel_like = \"register://electricity/0/activepower/l_?avg=15\"\n",
    "\n",
    "\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM\n",
    "(\n",
    "    SELECT\n",
    "        t1.boxid,\n",
    "        t1.channelid,\n",
    "        t1.value,\n",
    "        t1.year,\n",
    "        t1.week,\n",
    "        ROW_NUMBER() OVER (PARTITION BY (t1.boxid, t1.channelid, t1.year, t1.week) ORDER BY (t1.value) DESC) AS top,\n",
    "        -ROW_NUMBER() OVER (PARTITION BY (t1.boxid, t1.channelid, t1.year, t1.week) ORDER BY (t1.value) ASC) AS bottom,\n",
    "        CURRENT_TIMESTAMP AS processed_on \n",
    "     FROM (\n",
    "        SELECT \n",
    "            t0.BOXID AS boxid,\n",
    "            t0.CHANNELID AS channelid,\n",
    "            t0.WAARDE AS value,\n",
    "            YEAROFWEEKISO(t0.DATUMTIJD) AS year,\n",
    "            WEEKISO(t0.DATUMTIJD) AS week\n",
    "        FROM {data_config[\"database\"]}.{data_config[\"schema\"]}.{data_config[\"table\"]} t0\n",
    "        WHERE t0.CHANNELID LIKE '{channel_like}'\n",
    "         AND t0.DATUMTIJD >= DATE('{from_date}')\n",
    "         AND t0.DATUMTIJD < DATEADD('DAY', -DAYOFWEEKISO(CURRENT_DATE), CURRENT_DATE)\n",
    "--         AND t0.BOXID IN ('075.547-1', '069.509-1')\n",
    "--         LIMIT 100\n",
    "         ) t1\n",
    ") t2\n",
    "WHERE t2.top <= {n_extremes} OR t2.bottom >=-{n_extremes}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da40c1",
   "metadata": {
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_query = pd.read_sql(sql=query, con=snowflake_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d667179",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "pattern = channel_like\\\n",
    "    .replace(\"?\", \"\\?\")\\\n",
    "    .replace(\"/\", \"\\/\")\\\n",
    "    .replace(\"%\", \"(sumli|l[1,2,3])\")\n",
    "df_query[\"L\"] = df_query[\"CHANNELID\"].str.extract(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082a3fc",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df_query = df_query.apply(downcast, try_numeric=True, category=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c5053",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df_query.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b871ae",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df_query.to_parquet(parquet_file, partition_cols=[\"BOXID\", \"L\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319675d",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "cols = [\"BOXID\", \"VALUE\", \"YEAR\", \"WEEK\", \"TOP\", \"BOTTOM\", \"L\"]\n",
    "df_read = (\n",
    "    pd.read_parquet(parquet_file, columns=cols)\n",
    "    .query(\"TOP == 1 & L == 'sumli'\")\n",
    "    .drop(columns=[\"TOP\", \"BOTTOM\", \"L\"])\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd6fc9",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df_read.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd64e1",
   "metadata": {},
   "source": [
    "## get meta data about parquet for sake of speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbead15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "metadata = pq.read_metadata(\"../data/raw/BOXID=001.622-1/L=l1/7c3663dfe57547cb8fc54c33857b6caf.parquet\")\n",
    "\n",
    "# parquet_file = pq.ParquetFile(\"../data/raw/BOXID=001.622-1/L=l1/7c3663dfe57547cb8fc54c33857b6caf.parquet\")\n",
    "# metadata = parquet_file.metadata\n",
    "# metadata.row_group(0).column(6)\n",
    "\n",
    "## see parquet engine for possibilities to read _COMMON_METEDATA\n",
    "https://arrow.apache.org/docs/python/parquet.html?highlight=pyarrow%20parquet%20partition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ed99b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:spark] *",
   "language": "python",
   "name": "conda-env-spark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
