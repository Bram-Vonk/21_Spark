%% Generated by Sphinx.
\def\sphinxdocclass{report}
\IfFileExists{luatex85.sty}
 {\RequirePackage{luatex85}}
 {\ifdefined\luatexversion\ifnum\luatexversion>84\relax
  \PackageError{sphinx}
  {** With this LuaTeX (\the\luatexversion),Sphinx requires luatex85.sty **}
  {** Add the LaTeX package luatex85 to your TeX installation, and try again **}
  \endinput\fi\fi}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]


\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}


% Jupyter Notebook code cell colors
\definecolor{nbsphinxin}{HTML}{307FC1}
\definecolor{nbsphinxout}{HTML}{BF5B3D}
\definecolor{nbsphinx-code-bg}{HTML}{F5F5F5}
\definecolor{nbsphinx-code-border}{HTML}{E0E0E0}
\definecolor{nbsphinx-stderr}{HTML}{FFDDDD}
% ANSI colors for output streams and traceback highlighting
\definecolor{ansi-black}{HTML}{3E424D}
\definecolor{ansi-black-intense}{HTML}{282C36}
\definecolor{ansi-red}{HTML}{E75C58}
\definecolor{ansi-red-intense}{HTML}{B22B31}
\definecolor{ansi-green}{HTML}{00A250}
\definecolor{ansi-green-intense}{HTML}{007427}
\definecolor{ansi-yellow}{HTML}{DDB62B}
\definecolor{ansi-yellow-intense}{HTML}{B27D12}
\definecolor{ansi-blue}{HTML}{208FFB}
\definecolor{ansi-blue-intense}{HTML}{0065CA}
\definecolor{ansi-magenta}{HTML}{D160C4}
\definecolor{ansi-magenta-intense}{HTML}{A03196}
\definecolor{ansi-cyan}{HTML}{60C6C8}
\definecolor{ansi-cyan-intense}{HTML}{258F8F}
\definecolor{ansi-white}{HTML}{C5C1B4}
\definecolor{ansi-white-intense}{HTML}{A1A6B2}
\definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
\definecolor{ansi-default-inverse-bg}{HTML}{000000}

% Define an environment for non-plain-text code cell outputs (e.g. images)
\makeatletter
\newenvironment{nbsphinxfancyoutput}{%
    % Avoid fatal error with framed.sty if graphics too long to fit on one page
    \let\sphinxincludegraphics\nbsphinxincludegraphics
    \nbsphinx@image@maxheight\textheight
    \advance\nbsphinx@image@maxheight -2\fboxsep   % default \fboxsep 3pt
    \advance\nbsphinx@image@maxheight -2\fboxrule  % default \fboxrule 0.4pt
    \advance\nbsphinx@image@maxheight -\baselineskip
\def\nbsphinxfcolorbox{\spx@fcolorbox{nbsphinx-code-border}{white}}%
\def\FrameCommand{\nbsphinxfcolorbox\nbsphinxfancyaddprompt\@empty}%
\def\FirstFrameCommand{\nbsphinxfcolorbox\nbsphinxfancyaddprompt\sphinxVerbatim@Continues}%
\def\MidFrameCommand{\nbsphinxfcolorbox\sphinxVerbatim@Continued\sphinxVerbatim@Continues}%
\def\LastFrameCommand{\nbsphinxfcolorbox\sphinxVerbatim@Continued\@empty}%
\MakeFramed{\advance\hsize-\width\@totalleftmargin\z@\linewidth\hsize\@setminipage}%
\lineskip=1ex\lineskiplimit=1ex\raggedright%
}{\par\unskip\@minipagefalse\endMakeFramed}
\makeatother
\newbox\nbsphinxpromptbox
\def\nbsphinxfancyaddprompt{\ifvoid\nbsphinxpromptbox\else
    \kern\fboxrule\kern\fboxsep
    \copy\nbsphinxpromptbox
    \kern-\ht\nbsphinxpromptbox\kern-\dp\nbsphinxpromptbox
    \kern-\fboxsep\kern-\fboxrule\nointerlineskip
    \fi}
\newlength\nbsphinxcodecellspacing
\setlength{\nbsphinxcodecellspacing}{0pt}

% Define support macros for attaching opening and closing lines to notebooks
\newsavebox\nbsphinxbox
\makeatletter
\newcommand{\nbsphinxstartnotebook}[1]{%
    \par
    % measure needed space
    \setbox\nbsphinxbox\vtop{{#1\par}}
    % reserve some space at bottom of page, else start new page
    \needspace{\dimexpr2.5\baselineskip+\ht\nbsphinxbox+\dp\nbsphinxbox}
    % mimick vertical spacing from \section command
      \addpenalty\@secpenalty
      \@tempskipa 3.5ex \@plus 1ex \@minus .2ex\relax
      \addvspace\@tempskipa
      {\Large\@tempskipa\baselineskip
             \advance\@tempskipa-\prevdepth
             \advance\@tempskipa-\ht\nbsphinxbox
             \ifdim\@tempskipa>\z@
               \vskip \@tempskipa
             \fi}
    \unvbox\nbsphinxbox
    % if notebook starts with a \section, prevent it from adding extra space
    \@nobreaktrue\everypar{\@nobreakfalse\everypar{}}%
    % compensate the parskip which will get inserted by next paragraph
    \nobreak\vskip-\parskip
    % do not break here
    \nobreak
}% end of \nbsphinxstartnotebook

\newcommand{\nbsphinxstopnotebook}[1]{%
    \par
    % measure needed space
    \setbox\nbsphinxbox\vbox{{#1\par}}
    \nobreak % it updates page totals
    \dimen@\pagegoal
    \advance\dimen@-\pagetotal \advance\dimen@-\pagedepth
    \advance\dimen@-\ht\nbsphinxbox \advance\dimen@-\dp\nbsphinxbox
    \ifdim\dimen@<\z@
      % little space left
      \unvbox\nbsphinxbox
      \kern-.8\baselineskip
      \nobreak\vskip\z@\@plus1fil
      \penalty100
      \vskip\z@\@plus-1fil
      \kern.8\baselineskip
    \else
      \unvbox\nbsphinxbox
    \fi
}% end of \nbsphinxstopnotebook

% Ensure height of an included graphics fits in nbsphinxfancyoutput frame
\newdimen\nbsphinx@image@maxheight % set in nbsphinxfancyoutput environment
\newcommand*{\nbsphinxincludegraphics}[2][]{%
    \gdef\spx@includegraphics@options{#1}%
    \setbox\spx@image@box\hbox{\includegraphics[#1,draft]{#2}}%
    \in@false
    \ifdim \wd\spx@image@box>\linewidth
      \g@addto@macro\spx@includegraphics@options{,width=\linewidth}%
      \in@true
    \fi
    % no rotation, no need to worry about depth
    \ifdim \ht\spx@image@box>\nbsphinx@image@maxheight
      \g@addto@macro\spx@includegraphics@options{,height=\nbsphinx@image@maxheight}%
      \in@true
    \fi
    \ifin@
      \g@addto@macro\spx@includegraphics@options{,keepaspectratio}%
    \fi
    \setbox\spx@image@box\box\voidb@x % clear memory
    \expandafter\includegraphics\expandafter[\spx@includegraphics@options]{#2}%
}% end of "\MakeFrame"-safe variant of \sphinxincludegraphics
\makeatother

\makeatletter
\renewcommand*\sphinx@verbatim@nolig@list{\do\'\do\`}
\begingroup
\catcode`'=\active
\let\nbsphinx@noligs\@noligs
\g@addto@macro\nbsphinx@noligs{\let'\PYGZsq}
\endgroup
\makeatother
\renewcommand*\sphinxbreaksbeforeactivelist{\do\<\do\"\do\'}
\renewcommand*\sphinxbreaksafteractivelist{\do\.\do\,\do\:\do\;\do\?\do\!\do\/\do\>\do\-}
\makeatletter
\fvset{codes*=\sphinxbreaksattexescapedchars\do\^\^\let\@noligs\nbsphinx@noligs}
\makeatother



\title{`Spark project`}
\date{Dec 01, 2021}
\release{0.0.1}
\author{Bram Vonk}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{spark_logo}.png}\hspace*{\fill}}

\begin{sphinxadmonition}{note}{Note:}
\begin{DUlineblock}{0em}
\item[] This project is an Enexis case on forecasting load demand for distributon transformers.
\item[] The results should support grid planners with timely grid reinforcements and replacements.
\item[] The case is used as a graduation project for the Professional Education program of the Jheronimus Academy of Data Science
\end{DUlineblock}
\end{sphinxadmonition}


\chapter{General}
\label{\detokenize{general:general}}\label{\detokenize{general::doc}}

\section{About JADS}
\label{\detokenize{general:about-jads}}
\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{jads_logo}.png}\hspace*{\fill}}

This project is done in the context of the Professional Education Lead Program of the Jheronimus Academy of Data Science \sphinxhref{http://www.jads.nl}{{[}JADS{]}} as a graduation project.


\section{About Enexis}
\label{\detokenize{general:about-enexis}}
\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{enexis_logo}.png}\hspace*{\fill}}

\sphinxhref{http://www.enexis.nl}{Enexis} is a regulated regional distribution network operator (DNO) in the Netherlands, responsible for transporting electricity and gas to 2.6 million customers.

Enexis aims to keep the delivery af gas and electricity reliable, affordable and sustainable for all its customers.


\section{About the current situation}
\label{\detokenize{general:about-the-current-situation}}
Power is delivered via grid components such as cables and transformers (for electricity) to residential and industrial connections of our customers.

These grid components have to have a certain capacity. This is monitored by Grid Planners and if needed transformers are swapped for heavier ones, or cable connections are strengthened.

For decades this monitoring was done mainly by looking to historical yearly extremes.

However, the increasing growth rate of power demand and supply driven by emerging technologies as electrical vehicles (EV) and photovoltaics (PV), requires shorter monitoring periods and nowadays even forecasts.
Otherwise, there is no time for mitigating actions and customers will be out of power.


\section{About this project’s aim}
\label{\detokenize{general:about-this-project-s-aim}}
Enexis started a few years ago with the measurement of its distribution transformer population (in the project “distribution automation light” (DALI)).

Power measurements are since then available which enable monitoring ad hoc by the grid planners.

This project takes the next step by forecasting on that data in autumn if a transformer overloads in spring.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{autumn_spring_load}.png}\hspace*{\fill}}


\section{About the structure of this project}
\label{\detokenize{general:about-the-structure-of-this-project}}
This project and its documentation are set up around the CRoss Industry Standard Process for Data Mining \sphinxhref{https://www.datascience-pm.com/crisp-dm-2/}{{[}CRISP\sphinxhyphen{}DM{]}}.

It is an iterative process and this documentation focuses on the end result without ignoring the lessons learned along the way. The latter is generally noted at the end of every chapter.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{crisp_dm}.png}\hspace*{\fill}}


\section{Acknowledgements}
\label{\detokenize{general:acknowledgements}}
I would like to thank Jeroen the Mast for the valuable feedback and supervision.

Special thanks also goes out to PDEng candidate Akshaya Ravi for her technical support. Together with my buddy David Rijlaarsdam she provided me with helpful insights and discussions on the project.


\chapter{Business Understanding}
\label{\detokenize{business_understanding:business-understanding}}\label{\detokenize{business_understanding::doc}}

\section{Business Objectives}
\label{\detokenize{business_understanding:business-objectives}}
Enexis is a regulated DNO with a monopoly position regarding the distribution of electricity and gas.

The company wants to keep the delivery of electricity and gas:
\begin{itemize}
\item {} 
reliable

\item {} 
affordable

\item {} 
sustainable

\end{itemize}

This is realised by doing effective and efficient grid investments according to the Risk and Opportunity Based Asset Management method \sphinxhref{https://www.enexis.nl/over-ons/-/media/documenten/diversen/ip/enexis-netbeheer-ip-g-2020-2030-publicatie.pdf?modified=20200514053144}{{[}ROBAM{]}}.


\section{Situation Assessment}
\label{\detokenize{business_understanding:situation-assessment}}

\subsection{A changing environment}
\label{\detokenize{business_understanding:a-changing-environment}}
Power is delivered via grid components such as cables and transformers (for electricity) to residential and industrial connections of our customers.

These grid components have to have a certain capacity. This is monitored by Grid Planners and if needed transformers are swapped for heavier ones, or cable connections are strengthened.

For decades this monitoring was done mainly by looking to historical yearly extremes.

However, the increasing growth rate of power demand and supply driven by emerging technologies as electrical vehicles (EV) and photovoltaics (PV), requires shorter monitoring periods and nowadays even forecasts.
Otherwise, there is no time for mitigating actions and customers will be out of power.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{pv_cbs}.png}\hspace*{\fill}}

Solar power (PV) in The Netherlands (source: \sphinxhref{https://www.cbs.nl/nl-nl/nieuws/2020/10/productie-groene-elektriciteit-in-stroomversnelling}{CBS}).

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{ev_rvo}.png}\hspace*{\fill}}

Battery (B), Fuel Cell (FC) and Plugg\sphinxhyphen{}in Hybride (PH) Electric Vehicles (EV) in The Netherlands (source: \sphinxhref{https://www.rvo.nl/sites/default/files/2021/03/ElektrischRijdenop-de-weg-voertuigenenlaadpunten-jaaroverzicht2020.pdf}{RVO}).

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{hp_cbs}.png}\hspace*{\fill}}

Installed power of heat pumps (HP) in The Netherlands (source: \sphinxhref{https://opendata.cbs.nl/statline/\#/CBS/nl/dataset/82380NED/line?dl=55480}{CBS}).


\subsection{Impact on grid management}
\label{\detokenize{business_understanding:impact-on-grid-management}}
The more volatile and more rapidly increasing power flows, require Grid Planners more often to monitor if the minimum and maximum power is still withing the transformer’s capacity.
Otherwise, this will cause unsafe operating situations and it can lead to power outages.

Grid Planners expect a big increase of the number of transformers that reach their operating capacity in the upcoming years.
This in a time and environment were they are expected to make sure that Enexis is an enabler of the energy transition and not a show stopper.


\subsection{Opportunity for data science}
\label{\detokenize{business_understanding:opportunity-for-data-science}}
Since a few years Enexis started to deploy so called Distribution Automation Light Boxes (DALI).

With these measurement apparatus it is possible to monitor our distribution transformers near real time.

At the moment of writing 11k distribution transformers (of the total population of 35k) are equipped with these apparatus which are measuring 15 minute average voltages, currents and powers of each transformer.

This data (together with transformer metadata) enables us to automatically detect or even foresee earlier overloading of transformers.
It gives grid planners the opportunity to timely mitigate upcoming issues.


\section{Data Mining Goals}
\label{\detokenize{business_understanding:data-mining-goals}}

\subsection{Primary objective}
\label{\detokenize{business_understanding:primary-objective}}
More volatile power flows require a monitoring tool that forecasts transformer overloading.

The goal is to timely identify future overloading of transformers.


\subsection{Example Use Case}
\label{\detokenize{business_understanding:example-use-case}}
The project should result in a tool that is able to predict in autumn that a transformer will be overloaded in spring due to EV with a prediction interval.

The tool enables better planning of grid strengthening which prevents overloading of transformers (safety and reliability), foreseeing and better plan future work (costs) and enabling the energy transition better (sustainability).


\subsection{Business Value Diagram}
\label{\detokenize{business_understanding:business-value-diagram}}
Business value is created by the forecast model by enabling the preferred path for grid investments on the business value part (upper half) of the Business Flow Down Diagram below.

This path is possible by providing grid planners with a probability that a transformer will overload in the foreseeable future.

The model (lower half) will use historic DALI timeseries data to forecast transformer loading.
By comparing this forecast with capacity of the transformer possible overloading can be foreseen.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{value_flow_down}.png}\hspace*{\fill}}

Business Flow Down Diagram for the project.


\subsection{Requirements from Users}
\label{\detokenize{business_understanding:requirements-from-users}}
The developed product is only valuable if it is use dby the end users, who are the Grid Planners.
Therefore the following additional requirements and wishes are important:
\begin{itemize}
\item {} 
Grid Planners don’t want another tool to log into/install..

\item {} 
The presentation of results has to be quick (no long waiting times).

\item {} 
Results have to scalable up to 35k transformers.

\item {} 
The tool should be reliable (stable interface and accurate forecasts).

\item {} 
The model should be explainable.

\item {} 
The uncertainty of predictions should be available.

\item {} 
Results should be available for further use (e.g. importable for load flow tools).

\item {} 
The results should be sorted based on their urgency.

\item {} 
Forecast can also be made with limited transformer data.

\item {} 
Forecast horizon should be six months.

\end{itemize}


\subsection{Success Criteria}
\label{\detokenize{business_understanding:success-criteria}}
The project is a success if there is a tool that is being used by the Grid Planners that accurately forecasts overloading of transformers.

Usage of the tool can be measured by tracking users of the tool and by performing interview with the end users after deployment.
Accuracy is assessed by comparing forecasts with measurements.

On more detail the project is a success if:
\begin{itemize}
\item {} 
The model forecasts prediction intervals.

\item {} 
The working of the model can be explained clearly.

\item {} 
The prediction intervals ranges are acceptable to the Grid Planners.

\item {} 
The model can use prior information of the rest of the population if historic measurements are missing.

\item {} 
The computational burden is acceptable.

\end{itemize}


\section{Project Plan}
\label{\detokenize{business_understanding:project-plan}}

\subsection{Organisation}
\label{\detokenize{business_understanding:organisation}}
The involved stakeholders are:
\begin{itemize}
\item {} 
Grid Planners: The end users of the tool. Ad hoc, they will be updated/asked for input/their expertise on the field of grid planning and their needs. They assess if the project is a success.

\item {} 
Data Engineers:  To get the tool into production the ICT guidelines and processes within Enexis have to be respected. Expertise of the Data engineers is crucial in the second half of the project to get things into production/deployment.

\item {} 
Management: The direct manager enables Developer/Lead Bram to work two days a week on this project. Together with all other Enexis stakeholders they will be updated at the end of every sprint in the sprint review session.

\item {} 
Academic supervision: Jeroen de Mast will be the academic director that monitors progress and the academic level. Every three weeks there will be an one\sphinxhyphen{}on\sphinxhyphen{}one meeting to discuss progress and issues.

\item {} 
Academic support: PdEng candidate Akshaya Ravi of JADS is available for support on technical and academic issues. Together with a buddy from the Lead Track periodic meetings (every four weeks) will be planned, but also ad hoc issues will be discussed directly.

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=600\sphinxpxdimen]{{stakeholders}.png}\hspace*{\fill}}

The Stakeholders with meeting frequencies (heartbeat / ad hoc).


\subsection{Resources}
\label{\detokenize{business_understanding:resources}}
The project will take place in June, July, September, October and November 2021.
\begin{itemize}
\item {} \begin{description}
\item[{Personnel}] \leavevmode\begin{itemize}
\item {} 
Project lead / developer: Available 2 days per week.

\item {} 
Grid Planners: Available 2 hours per week.

\item {} 
Data engineers: Available 2 hours per week in October \sphinxhyphen{} November.

\item {} 
Supervision / support: Both available for a few hours every 3 weeks.

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{Data}] \leavevmode\begin{itemize}
\item {} 
DALI 15\sphinxhyphen{}minute measurement data.

\item {} 
Distribution transformer metadata (capacity).

\end{itemize}

\end{description}

\end{itemize}


\subsection{Requirements}
\label{\detokenize{business_understanding:requirements}}
The tool should be implemented in such way that it is:
\begin{itemize}
\item {} 
Maintainable: The code has to have docstrings and unit tests.

\item {} 
Scalable: The tool has to be able to process 35k transformers.

\item {} 
Deployable: The tool has to be able to go in production according to the Enexis standards (Test\sphinxhyphen{}Acceptance\sphinxhyphen{}Production).

\end{itemize}


\subsection{Assumptions}
\label{\detokenize{business_understanding:assumptions}}\begin{itemize}
\item {} 
DALI data is available without huge quality issues during the project

\item {} 
Weekly extremes on transformer data is an acceptable aggregation level for capacity planning.

\item {} 
Data Engineering has capacity for several hours a week for support between September and December.

\item {} 
The computational burden for probabilistic models is no problem regarding the computational power available.

\end{itemize}


\subsection{Risks and Contingencies}
\label{\detokenize{business_understanding:risks-and-contingencies}}\begin{itemize}
\item {} \begin{description}
\item[{Lead / developer has just become a father (is technically up to September on parental leave) and bought a house that has to be renovated. This could result in lower availability for this project.}] \leavevmode\begin{itemize}
\item {} 
Mitigation: None.

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{Grid Planners are immensely occupied with the current challenges in the grid. Although not a lot of time is required, it might be that other activities have higher priority than this project.}] \leavevmode\begin{itemize}
\item {} 
Mitigation: Be clear and direct regarding expectations and communications and limit the effort and time for this project for Grid Planners without giving in on quality/input.

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{Data Engineers are also loaded with work and might not have time/resources available.}] \leavevmode\begin{itemize}
\item {} 
Mitigation: It is essential to request capacity in the beginning of the project, although they will be involved only in the second half

\end{itemize}

\end{description}

\item {} 
There is no use of sensitive data in this project regarding privacy (GDPR) or security. DALI data is allowed to be used. Credentials are not embedded in code and access to data sources is restricted by design.

\end{itemize}


\subsection{Costs and Benefits}
\label{\detokenize{business_understanding:costs-and-benefits}}\begin{itemize}
\item {} 
Data collection: Data is available in an existing database. Only querying is needed, no active additional data collection.

\item {} 
Implementation: Open source software is used besides already licensed applications. Only computation power will cost additionally. More details will be available after a first proof of concept.

\end{itemize}


\subsection{Implementation Concept}
\label{\detokenize{business_understanding:implementation-concept}}
The stool is split into three steps to tackle the amount of data available, but still make the results manageable:
\begin{itemize}
\item {} 
Preprocessing: To condense 15 minute load averages into weekly extremes (minimum and maximum).

\item {} 
Forecasting: To fit a model on the aggregated data and create forecasts.

\item {} 
Dashboarding: To display (forecast) results to the end user.

\end{itemize}

In between steps results are stored in a Snowflake database.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{process_steps}.png}\hspace*{\fill}}

The proposed steps for implementation of the tool.


\subsection{Planned Milestones}
\label{\detokenize{business_understanding:planned-milestones}}

\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Scheduled project milestones for 2021.}\label{\detokenize{business_understanding:id1}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{25}{100}|\X{25}{100}|\X{50}{100}|}
\hline
\sphinxstyletheadfamily 
week
&\sphinxstyletheadfamily 
CRISP\sphinxhyphen{}DM step
&\sphinxstyletheadfamily 
detail
\\
\hline
26
&
Business Understanding
&\\
\hline
29
&
Data understanding
&
Go / No Go
\\
\hline
–
&
–
&
Summer break
\\
\hline
36
&
Data Preparation
&\\
\hline
39
&
Modeling
&\\
\hline
42
&
Evaluation
&
Go / No Go
\\
\hline
45
&
Deployment
&\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\chapter{Data Understanding}
\label{\detokenize{data_understanding:data-understanding}}\label{\detokenize{data_understanding::doc}}

\section{Initial Data Collection}
\label{\detokenize{data_understanding:initial-data-collection}}
The goal is to forecast accurately maximum and minimum loading of transformers.

There is 15\sphinxhyphen{}minute average data available of 11k transformers.

The maximum and minimum loading is not needed on this detailed level.
According to the Grid Planners, weekly or monthly extreme details are more than enough.

For this first model to forecast transfer loading no external variables will be used as input for the model.
Only historic data will be used (with metadata to extract de capacity of the transformer).

Data is available in Snowflake.
A Jupyter Notebook pandas with a SQLAlchemy engine is used for the data collection from Snowflake.

Credentials are available via Vault in the Enexis domain.


\subsection{Measurement Data Source}
\label{\detokenize{data_understanding:measurement-data-source}}
In a Snowflake database the following data is available:


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Snowflake data source details.}\label{\detokenize{data_understanding:id1}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{25}{50}|\X{25}{50}|}
\hline

Database
&
DB\_CDWH\_P
\\
\hline
Schema
&
CDWH\_4\_BDM
\\
\hline
Table
&
BDM\_DALI\_METINGEN
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\subsection{Metadata Data Source}
\label{\detokenize{data_understanding:metadata-data-source}}
In a Snowflake database the following metadata is available:


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Snowflake data source details.}\label{\detokenize{data_understanding:id2}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{25}{50}|\X{25}{50}|}
\hline

Database
&
DB\_CDWH\_P
\\
\hline
Schema
&
CDWH\_5\_INF\_MEETDATA\_E View: DIM\_DALI\_BOX\_VW
\\
\hline
Table
&
DIM\_DALI\_BOX\_VW
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\section{Data Description}
\label{\detokenize{data_understanding:data-description}}

\subsection{Measurement Data Details}
\label{\detokenize{data_understanding:measurement-data-details}}
The measurements are available since Q2 2018.

Since then more and more transformers were equiped with DALI boxes and at the moment of writing (Q3 2021) a total number of 10,992 boxes are measured.
Measurements on open doors (from safety perspective important) and currents, voltages and powers accumulated up to 89,052,020,404 records in the Snowflake table.

For this project we focus first on the active power on a transformer om the medium voltage connection side.

The power is available for all three power phases as well as the sum of them.

Below are the fields of interest given that are queried from the aforementioned table.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{DALI table fields of interest.}\label{\detokenize{data_understanding:id3}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{25}{100}|\X{25}{100}|\X{50}{100}|}
\hline
\sphinxstyletheadfamily 
Field o.i.
&\sphinxstyletheadfamily 
Type
&\sphinxstyletheadfamily 
Example
\\
\hline
BOXID
&
VARCHAR
&
ESD.000240\sphinxhyphen{}2
\\
\hline
CHANNELID
&
VARCHAR
&
register://electricity/0/activepower/sumli?avg=15
\\
\hline
WAARDE
&
DOUBLE
&
\sphinxhyphen{}3.408062
\\
\hline
DATUMTIJD
&
TIMESTAMPTZ
&
2021\sphinxhyphen{}05\sphinxhyphen{}12 07:45:00.000000000
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\subsection{Metadata Details}
\label{\detokenize{data_understanding:metadata-details}}
In the metadata table there are 15,058 records present.

Only 9,920 boxids are operational and have a nominal power correctly registered.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Metadata table fields of interest.}\label{\detokenize{data_understanding:id4}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{25}{100}|\X{25}{100}|\X{50}{100}|}
\hline
\sphinxstyletheadfamily 
Field o.i.
&\sphinxstyletheadfamily 
Type
&\sphinxstyletheadfamily 
Example
\\
\hline
BOXID
&
VARCHAR
&
ESD.000240\sphinxhyphen{}2
\\
\hline
BOX\_BEDRIJFSSTATUS
&
VARCHAR
&
in bedrijf
\\
\hline
IN\_BEDRIJFSNAME\_DATUMTIJD
&
TIMESTAMPTZ
&
2021\sphinxhyphen{}05\sphinxhyphen{}12 07:45:00.000000000
\\
\hline
VESTIGING
&
VARCHAR
&
Breda
\\
\hline
VERMOGEN\_NOMINAAL
&
NUMBER
&
400
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\section{Data Exploration}
\label{\detokenize{data_understanding:data-exploration}}
The measurement data is up\sphinxhyphen{}to\sphinxhyphen{}date, but has missing values in two moments in time (both in 2021). This issue was discovered and is addressed.

For the project it won’t be a huge issue, since the data is aggregated to weekly extremes.
It will will cause extremes to be less extreme if (a lot of) data is missing. Only if data is missing for a whole week, there will also be missing data in the aggregated set.

In both cases (outlier and missing data) the model can handle this.

For timeseries modelling it is advised to have at least two periods (years in this case) of measurement data.

As the figure below shows, this might be a problem eventually. One of the challenges is therefore to explore if prior knowledge of the population can overcome this issue.

In the figure below the completeness of the data over time is given for the transformers in the area of Breda.
On the vertical axis the transformers are shown ordered by the time they got operational. On the horizontal axis the time is given. In color the completeness is given per week: Darkblue (value 1) means that all data was present, towards white (value 0) means no data at all.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{dq_completeness}.jpeg}\hspace*{\fill}}

Completeness for DALI data in the service area of Breda.


\section{Data Quality}
\label{\detokenize{data_understanding:data-quality}}
Beside the missing data described above, the data quality (of the 15\sphinxhyphen{}minute power averages) seems like expected.
The reason is probably that the 15\sphinxhyphen{}minute averaging already smooths out the extreme (short circuit) values and measurement errors.

Although sometimes outliers can still be seen in the data (which can propagate into the weekly extremes as shown on the figure below).
Taking not only the extremes, but also the second highest/lowest value per week for robustness did not make a lot of difference (probably also due to the aforementioned smoothing).

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{dq_outlier}.png}\hspace*{\fill}}

Example of weekly extremes with an outlier for the maximum in July 2020.


\chapter{Data Preparation}
\label{\detokenize{data_preparation:data-preparation}}\label{\detokenize{data_preparation::doc}}
The data preparation step focuses on converting raw measurement data with a frequency of 15 minutes into weekly extremes and preparing these extremes to be usable input for the forecasting model.

Initially the whole history is aggregated and stored in a Snowflake database. After that updates are done every month / week.

\noindent{\hspace*{\fill}\sphinxincludegraphics[height=250\sphinxpxdimen]{{process_data_preparation}.png}\hspace*{\fill}}

The data preparation step resulting in weekly aggregated data.


\section{Data Selection}
\label{\detokenize{data_preparation:data-selection}}
Columns described in \DUrole{xref,std,std-ref}{Data Understanding} are selected from the measurement () and metadata tables.

From the measurement data only data is selected from DALI boxes that have nominal power registered in the metadata table and that are in operation ({\hyperref[\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.read_meta}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.utils.snowflake.read\_meta()}}}}}). Both data and metadata are needed to indicate future overloading and add value to Grid Planners.

As mentioned only the active power (P) on medium voltage side is used initially. Apparent power (S) is preferred (for a more fair comparison with the nominal power), but since this is 15 minute average data, this is hard to reconstruct.

In this step the separate power phases are selected and processed as well as the sum of the phases ({\hyperref[\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.make_week_extremes_query}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.utils.snowflake.make\_week\_extremes\_query()}}}}}).

Only the 15 minute average channels are selected for preprocessing.


\section{Data Cleaning}
\label{\detokenize{data_preparation:data-cleaning}}
No data cleaning is performed on the raw data before aggregation, but data is checked and cleaned on the following after reading it in ({\hyperref[\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.load_data}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.load\_data()}}}}}) and before being used by a model for forecasting:
\begin{itemize}
\item {} 
Data of extremes (minimum or maximum) having the value of zero in the beginning of the series are removed ({\hyperref[\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.remove_leading_idling}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.remove\_leading\_idling()}}}}}). This is for example the case if a DALI box is in operation, but its transformer is not.

\item {} 
Only data is used that has a history of more than two years ({\hyperref[\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.too_short}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.too\_short()}}}}}). This will ensure in this stage that the seasonality (sub)model has enough data to tune on.

\item {} 
Only data is used of transformers that have a measurement in their history with an absolute value higher than half the transformer capacity ({\hyperref[\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.too_small}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.too\_small()}}}}}).

\end{itemize}

Duplicate data (can only be created by updating the extreme table) is not an issue for the model and will not be eliminated.

Missing data is neither a problem for the model and is also not imputed.


\section{Data Construction}
\label{\detokenize{data_preparation:data-construction}}
From the raw 15\sphinxhyphen{}minute data the weekly minimum and maximum are determined. This is done per channel and boxid ({\hyperref[\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.make_week_extremes_query}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.utils.snowflake.make\_week\_extremes\_query()}}}}}).
The week definition used is the ISO\sphinxhyphen{}week since this is always a full week.

A SQL query aggregates and writes the result asynchronously on the Snowflake database. This can be done in batch for all historic measurements ({\hyperref[\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.create_week_extremes}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.utils.snowflake.create\_week\_extremes()}}}}}), but the created table can also be updated per week ({\hyperref[\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.update_week_extremes}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.utils.snowflake.update\_week\_extremes()}}}}}).


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Snowflake table details for weekly extremes data.}\label{\detokenize{data_preparation:id1}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{25}{50}|\X{25}{50}|}
\hline

Database
&
DB\_DATASCIENCE\_P
\\
\hline
Schema
&
DATASCIENCE\_1\_ETL
\\
\hline
Table
&
DS\_SPARK\_DALI\_WEEK\_EXTREMES
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

The fields of the table are listed below. The table is clustered by BOXID and L.
The amount of rows is condensed from 89,052,020,404 to 3,457,856 records.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Extremes table fields.}\label{\detokenize{data_preparation:id2}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{25}{100}|\X{25}{100}|\X{50}{100}|}
\hline
\sphinxstyletheadfamily 
Field
&\sphinxstyletheadfamily 
Type
&\sphinxstyletheadfamily 
Example
\\
\hline
BOXID
&
VARCHAR
&
ESD.000240\sphinxhyphen{}2
\\
\hline
L
&
VARCHAR
&
sumli
\\
\hline
YEAR
&
NUMBER
&
2021
\\
\hline
WEEK
&
NUMBER
&
53
\\
\hline
PROCESSED\_ON
&
TIMESTAMPTZ
&
2021\sphinxhyphen{}05\sphinxhyphen{}12 07:45:00.000000000
\\
\hline
MAX
&
DOUBLE
&
678.90
\\
\hline
MIN
&
DOUBLE
&
123.45
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\section{Data Integration}
\label{\detokenize{data_preparation:data-integration}}
Since no additional data sources are used, no joins or merges are required.


\section{Data Formatting}
\label{\detokenize{data_preparation:data-formatting}}
The model does not demand an order (e.g. by year and week) of the data.
For the modelling stage the data is queried from the table in {\hyperref[\detokenize{data_preparation:data-construction}]{\sphinxcrossref{Data Construction}}}

Consecutively, a date column is constructed from the ISO year and week format with day==1.

The extra columns period and model\_var are assigned and filled with the values “history”, “observed” respectively for measurement data.
This is in preparation for long formatting and concatenating forecast results in a later stage ({\hyperref[\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.format_data}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.format\_data()}}}}}).

An example of the loaded extreme data is shown below

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{loaded_extremes}.png}\hspace*{\fill}}

The format of the loaded extremes data.


\section{Data Updating Process}
\label{\detokenize{data_preparation:data-updating-process}}
The weekly extremes can be updated on a weekly (or longer) basis.

By running {\hyperref[\detokenize{autoapi/src/preprocess/update_extremes/index:module-src.preprocess.update_extremes}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.preprocess.update\_extremes()}}}}} the function {\hyperref[\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.update_week_extremes}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.utils.snowflake.update\_week\_extremes()}}}}} is called.
This will will trigger the following steps which update the weekly extremes Snowflake table:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{preprocessing_details}.png}\hspace*{\fill}}

The detailed process to create and assess load forecasts.


\chapter{Modeling}
\label{\detokenize{modeling:modeling}}\label{\detokenize{modeling::doc}}

\section{Modeling Technique}
\label{\detokenize{modeling:modeling-technique}}
The Grid Planners are looking to data driven forecast with a uncertainty indication as mentioned before.
This is visualized as a concept in the figure below.
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{autumn_spring_load}.png}\hspace*{\fill}}
\end{quote}

A possible output of the model visualized.


\subsection{Input Features}
\label{\detokenize{modeling:input-features}}
The Grid Planners want to have a result dat is based on real observed data.
Or, to make it more explicit: Data that has been measured and not data from possible scenarios with a wide range of uncertainty.

Another suggestion was made to use (historic) weather data as an exogenous feature / input for the model.
However, this is not data we have available with a reasonable confidence for the forecast horizon (in the future).
And seasonality can also be captured from the observed data itself for different timeseries models.

Therefore, the model only uses historic DALI measurement data.


\subsection{Fit\sphinxhyphen{}Predict Process}
\label{\detokenize{modeling:fit-predict-process}}
A model will be fitted / tuned for every DALI measurement extremes since every transformer has it’s own unique signal ({\hyperref[\detokenize{autoapi/src/forecast/forecast/index:src.forecast.forecast.determine_estimates}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.forecast.forecast.determine\_estimates()}}}}}).

A model is trained on observed data, a forecast is made and stored and finally the trained model is discarded ({\hyperref[\detokenize{autoapi/src/forecast/forecast/index:src.forecast.forecast.forecast}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.forecast.forecast.forecast()}}}}}).

\noindent{\hspace*{\fill}\sphinxincludegraphics[height=250\sphinxpxdimen]{{process_modeling}.png}\hspace*{\fill}}

The weekly extremes are loaded for tuning the model. The model forecasts are afterwards stored in a Snowflake database.

The next time a forecast is required, new data is available and a new model will be fitted and used for forecasting.


\subsection{Model Environment}
\label{\detokenize{modeling:model-environment}}
A probabilistic approach has been implemented to fulfill the wish to forecast and display uncertainty rather than a point estimate.

From the main probabilistic toolboxes (STAN, EDWARD2, Pyro, TensorFlow2 Probability) \sphinxhref{https://docs.pymc.io/en/stable/}{PyMC3} was used for it’s extensive documentation.

A future step could be to transfer the model into TensorFlow2 Probability since PyMC3 is not the most recent toolbox anymore.


\subsection{Generalized Additive Model Concept}
\label{\detokenize{modeling:generalized-additive-model-concept}}
To address the explainability of the model, a similar approach as \sphinxhref{https://facebook.github.io/prophet/}{Facebook Prophet} is used.

The model is a Generalized Additive Model \sphinxhref{https://en.wikipedia.org/wiki/Generalized\_additive\_model}{(GAM)} that consists of a trend / drift and seasonality component (and an error component).

The translation to PyMC3 of \sphinxhref{https://www.ritchievink.com/blog/2018/10/09/build-facebooks-prophet-in-pymc3-bayesian-time-series-analyis-with-generalized-additive-models/}{Richie Vink} was used as a basis.

The GAM approach makes it easy to decompose the different components of the timeseries and show the Grid Planners the effect of the drift and seasons separately.


\section{Test Design}
\label{\detokenize{modeling:test-design}}
To evaluate the model the observed data is split into a train and test set based in the forecast horizon ({\hyperref[\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.split_last}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.split\_last()}}}}}).

After splitting the train set is tested again for not being too short (at least two years: {\hyperref[\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.too_short}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.too\_short()}}}}}).
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=600\sphinxpxdimen]{{train_test}.png}\hspace*{\fill}}
\end{quote}

The split of measurement data into train and test data.

The test set is only used to validate forecasting results.

The train set is used to train / fit / tune the model.


\section{Model}
\label{\detokenize{modeling:model}}

\subsection{Generalized Additive Model}
\label{\detokenize{modeling:generalized-additive-model}}
The GAM model used is ({\hyperref[\detokenize{autoapi/src/model/model/index:src.model.model.create_model}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.model.model.create\_model()}}}}}):
\begin{equation*}
\begin{split}\sigma_\epsilon \sim Uniform(lower=0, \:upper=1)\end{split}
\end{equation*}\begin{equation*}
\begin{split}\Sigma\:|\:drift, yearly, \sigma_\epsilon = Normal(\mu=drift + yearly, \:sd=\sigma_\epsilon)\end{split}
\end{equation*}
The additive naming is explicit in this notation.

The error component has a has a bandwidth of \(\sigma_\epsilon\).


\subsubsection{Drift Component}
\label{\detokenize{modeling:drift-component}}
According to the Grid Planners a increasing growth is more and more common due to the energy transition.

Therefore, a stable drift model ({\hyperref[\detokenize{autoapi/src/model/model/index:src.model.model.drift_model}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.model.model.drift\_model()}}}}}) is used that can mimic that.

An exponential function resulted in divergence during the model tuning, but a second order taylor series makes the model convergent and stable.

The drift component model with a taylor series with the order of \(n\) is described as:
\begin{equation*}
\begin{split}X_{drift}(t) = [t^0, ...,  t^n]\end{split}
\end{equation*}\begin{equation*}
\begin{split}\beta_{drift} \sim Normal(\mu=0, \:sd=0.5)\end{split}
\end{equation*}\begin{equation*}
\begin{split}drift\:|\:\beta_{drift} = X_{drift}(t)\:\beta_{drift}\end{split}
\end{equation*}
For modelling a drift that has the described growth, a polynomial with order \(n=2\) is used.


\subsubsection{Yearly Component}
\label{\detokenize{modeling:yearly-component}}
Since the data has been aggregated into weekly extremes, the only seasonality to model is the yearly pattern.

The yearly seasonality is modeled with \(n\) order fourier series ({\hyperref[\detokenize{autoapi/src/model/model/index:src.model.model.seasonality_model}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.model.model.seasonality\_model()}}}}}).

This is based on the work of \sphinxhref{https://www.ritchievink.com/blog/2018/10/09/build-facebooks-prophet-in-pymc3-bayesian-time-series-analyis-with-generalized-additive-models/}{Richie Vink}.

The yearly seasonality model is described as:
\begin{equation*}
\begin{split}X_{yearly}(t) = [cos(\frac{2 \pi 1 t}{T}), ..., sin(\frac{2 \pi n t}{T})]\end{split}
\end{equation*}\begin{equation*}
\begin{split}\beta_{yearly} \sim Normal(\mu=0, \:sd=1)\end{split}
\end{equation*}\begin{equation*}
\begin{split}drift\:|\:\beta_{yearly} = X_{yearly}(t)\:\beta_{yearly}\end{split}
\end{equation*}
Here the \(T\) is the period of the seasonality in unit of time of the data.

The unit of time in this case is a week for the data and a year in weeks is \(T=52.1775\).

The order taken for the fourier series is \(n=5\).


\subsubsection{Enabling Forecasts}
\label{\detokenize{modeling:enabling-forecasts}}
The model parameters (\(\beta\))’s can now be tuned to produce the model is most likely to produce the observed (measurement) data.

To forecasting, the model also needs to produce beyond the timestamps it has been tuned on.

The PyMC3 model can cope with this by feeding it with timestamps that are extrapolated for the forecasting horizon ({\hyperref[\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.extrapolate_timestamps}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.extrapolate\_timestamps()}}}}}).

The matching observations (measurements) can be intentionally filled with NaN’s.

In the model PyMC3 will name them \(\Sigma_{missing}\).
(This characteristic makes the model also robust against missing data).

By sampling the posterior predictive after tuning, also samples are generated for the extrapolated forecast timestamps ({\hyperref[\detokenize{autoapi/src/forecast/forecast/index:src.forecast.forecast.determine_estimates}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.forecast.forecast.determine\_estimates()}}}}}).


\subsubsection{Total model Σ}
\label{\detokenize{modeling:total-model}}\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=600\sphinxpxdimen]{{graph_model}.png}\hspace*{\fill}}
\end{quote}

The total model visualized.

Two separate GAM models \(\Sigma\) ({\hyperref[\detokenize{autoapi/src/model/model/index:src.model.model.create_model}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.model.model.create\_model()}}}}}) are used for the weekly minimum and maximum.

The visual above shows the total GAM model with a polynomial drift order \(n=2\) (the bias of order 0 explains \(N+1=3\)) and a fourier order of \(n=5\) (the sine and cosine parts explain \(N*2=10\)).

The number of observations (weeks of measurements for this case) is 121 and the forecasting horizon is just more than six months (27 weeks).


\subsubsection{Formatting Results}
\label{\detokenize{modeling:formatting-results}}
From the model posterior predictive samples are drawn for all timestamps (also measurement timestamps, 1000 samples per timestamp).

From the posterior samples, the quantile bands are determined (\sphinxcode{\sphinxupquote{src.forecast.format.make\_quantile\_bands()}}).
This reduces the data storage.

The upper and lower limits of the quantile bands are then stored in the same format as the input (\sphinxcode{\sphinxupquote{src.forecast.format.format\_model\_estimates()}}).

The input of the model and the output are then concatenated together.
This eases the visualization later.
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{data_stored}.png}\hspace*{\fill}}
\end{quote}

The concatenated input and result.


\section{Model Assessment}
\label{\detokenize{modeling:model-assessment}}
The following model findings are most salient:
\begin{itemize}
\item {} \begin{description}
\item[{The model converges during tuning and gives feasible results.}] \leavevmode\begin{itemize}
\item {} 
Exponential drift function tuning will not converge.

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{The computational burden on a CPU to tune and forecast both extremes is 1:24.}] \leavevmode\begin{itemize}
\item {} 
CPU: 2 GHz Quad\sphinxhyphen{}Core Intel Core i5

\item {} 
RAM: 16 GB

\end{itemize}

\end{description}

\item {} 
The model is fairly insensitive to outliers and missing data.

\item {} 
The splitting of observations into train and test set works.

\item {} 
The extrapolation with the forecasting horizon works.

\item {} \begin{description}
\item[{An pure additive model may not be sufficient.}] \leavevmode\begin{itemize}
\item {} 
Growth also increases the yearly component (see visualization below).

\item {} 
A pure multiplicative diverges.

\item {} 
A hybrid model (addition of a small fraction of a multiplicative model) might be an option.

\end{itemize}

\end{description}

\end{itemize}

A visualization of the results is shown in the figure below which shows most of the aforementioned points:
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{additive_model}.png}\hspace*{\fill}}
\end{quote}

An visualization of the measurements (history) and forecast (estimates).
Measurements from the train and test set are plotted.


\subsection{Improvement suggestions}
\label{\detokenize{modeling:improvement-suggestions}}
The following ideas could result in a better model:
\begin{itemize}
\item {} 
Implementing a hybrid additive\sphinxhyphen{}multiplicative model for dealing with the growing seasonality.

\item {} \begin{description}
\item[{Adding a extra component to detect temporarily bypass switching of loads of other transformers.}] \leavevmode\begin{itemize}
\item {} 
This could be implemented by estimating parameters of a \sphinxhref{https://en.wikipedia.org/wiki/Rectangular\_function}{rectangular function}.

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{Making more recent observations more relevant for slowly changing loading patterns}] \leavevmode\begin{itemize}
\item {} 
Possibilities are to mimic weights with \sphinxhref{https://discourse.pymc.io/t/how-to-run-logistic-regression-with-weighted-samples/5689}{pm.Potential} or \sphinxhref{https://discourse.pymc.io/t/pm-sample-posterior-predictive-not-working-with-weights/5698/11}{pm<distribution>(tau=weights)}.

\end{itemize}

\end{description}

\item {} 
Using the population seasonality as a \sphinxhref{https://minimizeregret.com/post/2019/04/16/modeling-short-time-series-with-prior-knowledge/}{prior} in case of a short history of observations.

\item {} 
Using by\sphinxhyphen{}pass dummy model for \sphinxhref{https://docs.pymc.io/en/stable/pymc-examples/examples/generalized\_linear\_models/GLM-robust-with-outlier-detection.html}{outlier robustness}.

\end{itemize}


\chapter{Evaluation}
\label{\detokenize{evaluation:evaluation}}\label{\detokenize{evaluation::doc}}
This section discusses the evaluation of the implemented model, the assessments of results and a reflection on the learning objectives for the study course this project was part of.


\section{Model Evaluation}
\label{\detokenize{evaluation:model-evaluation}}
The evaluation of results has not been done with a error criteria (e.g. MAE, MAPE), but only visual.
This will be done in the near future, when additional model improvements are implemented and needed to be assessed.

This section will discuss briefly the model


\subsection{Model Robustness}
\label{\detokenize{evaluation:model-robustness}}
The model as it is described before is stable for all transformer forecasts: It converges for all transformer timeseries that are used.

A robust model for all 11k transformers is essential if models are trained and used without human supervision and results are automatically assessed.
An experiment of an exponential function for the drift sub\sphinxhyphen{}model was implemented, but far from stable.

The model is also robust when data is missing. Even missing data for long periods will result is a reasonable forecast:
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{missing_data_results}.png}\hspace*{\fill}}
\end{quote}

The model results after data accidentally was removed from the source database.


\subsection{Model Results}
\label{\detokenize{evaluation:model-results}}
The model forecasts neatly the median and quantile bands as intended.

However, it will always be a model trained on historical, observed data, and forecasts will always be off.
Partially, this can be due to model imperfections, for which improvements are suggested earlier, partially this is due to the reality opf the outside world.

The grid planners were shown different off\sphinxhyphen{}results to make them aware of the limiting accuracy and reliability of the models and their forecasts.

This was visually shown by the following actions:
The results were assessed by splitting the observed data into a train and test set, using a model based on the train set and comparing the results with the test set.
The performance of for the different transformers of course also differs, but an example can be seen in the following figure:
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{validation}.png}\hspace*{\fill}}
\end{quote}

Forecasts made by a model based on data before May 2021, validated with later observation.


\subsection{Model Improvements}
\label{\detokenize{evaluation:model-improvements}}
Stepping through the CRISP\sphinxhyphen{}DM cycle resulted in several insights to for model improvement.
The most promising suggestions for model improvement are:
\begin{itemize}
\item {} 
Improving tuning and forecasting time.

\item {} 
Implementing hybrid additive\sphinxhyphen{}multiplicative model for dealing with the growing seasonality.

\item {} 
Adding a extra component to detect temporarily bypass switching of loads of other transformers.

\item {} 
Making more recent observations more relevant for slowly changing loading patterns

\item {} 
Using the population seasonality as a \sphinxhref{https://minimizeregret.com/post/2019/04/16/modeling-short-time-series-with-prior-knowledge/}{prior} in case of a short history of observations.

\item {} 
Using by\sphinxhyphen{}pass dummy model for \sphinxhref{https://docs.pymc.io/en/stable/pymc-examples/examples/generalized\_linear\_models/GLM-robust-with-outlier-detection.html}{outlier robustness}.

\end{itemize}


\section{Results Evaluation}
\label{\detokenize{evaluation:results-evaluation}}
This section discusses the assessment and prioritization of the forecasts and the implementation within the process.


\subsection{Results Prioritization}
\label{\detokenize{evaluation:results-prioritization}}
The are potentially 11k models that all forecast six months ahead.

These are numbers too high to be assessed by grid planners one by one.
Therefore the forecast results are automatically assessed and ordered by urgency.

The grid planners gave as input that they wanted overloaded transformers ordered by the time the potential overloading was expected.

Firstly, the definition of potential (over)loading was agreed on to be the following:
\begin{itemize}
\item {} 
Potential loading is the maximum absolute of the forecast quantile bands divided by the transformer capacity

\item {} 
Potential overloading is the potential loading is greater than one.

\end{itemize}

Potential overloaded transformers can now be ordered by the point in time when they reach this limit.

Then there are also transformers that will never potentially overload.
The forecasts of these transformers are simply ordered by potential loading

To summarize into steps:
\begin{itemize}
\item {} 
Determine absolute value of the forecasted quantile bands.

\item {} 
Divide the found value by the transformer capacity.

\item {} 
Clip the results on the value of one.

\item {} 
Find value and index (timestamp) of the maximum.

\item {} 
Order the transformers by timestamp (first) and value (second).

\end{itemize}

The result of this prioritization is shown below.
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=300\sphinxpxdimen]{{ordered_transformers}.png}\hspace*{\fill}}
\end{quote}

Transformers ordered by potential (over)loading.

The result is that grid planners have an prioritized list of transformers, with on top the transformers that are probably overloading soon.


\subsection{Evaluation Implementation}
\label{\detokenize{evaluation:evaluation-implementation}}
The assessments of the forecasts which results in the ordered list ({\hyperref[\detokenize{autoapi/src/forecast/assess/index:src.forecast.assess.asses_forecasts}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.forecast.assess.asses\_forecasts()}}}}}) is done directly after forecasting.
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{forecasts_assessment}.png}\hspace*{\fill}}
\end{quote}

The process steps of the final product.

The result is stored separately in a Snowflake database table ({\hyperref[\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.read_forecast_meta}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.utils.snowflake.read\_forecast\_meta()}}}}}).
This way the data can quickly be loaded by the dashboard application and presented to the grid planners.


\section{Presentation of Results}
\label{\detokenize{evaluation:presentation-of-results}}
A dashboard is made by using Panel and Altair libraries ({\hyperref[\detokenize{autoapi/src/plot/dashboard/index:module-src.plot.dashboard}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{src.plot.dashboard}}}}}).

The dashboard presents the ordered list of all transformers and a figure of a forecast for an individual transformer.
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{dashboard}.png}\hspace*{\fill}}
\end{quote}

The dashboard with on the left the ordered transformers and on the right the tabs with forecast and decomposed trend and yearly pattern for minimum and maximum.

The list can be filtered by Enexis sub\sphinxhyphen{}service area, since grid planners are generally responsible for an area within these areas and not interested in the whole service area.
Other ordering is possible if the grid planner desires.

After selection of a transformer, the measured weekly extremes, the forecast six months ahead, and the transformer capacity are displayed in the first tab.

One can zoom in and pan de plot and tooltips show up on historic measurement data.

If the grid planner is interested, he can view in the other tabs the decompositions (drift / trend and yearly pattern) for the weekly minimum and maximum.
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{dashboard_min}.png}\hspace*{\fill}}
\end{quote}

The dashboard with the sub\sphinxhyphen{}service area filtering and the minimum decomposition tab of the dashboard.


\subsection{Improvements on Presentation}
\label{\detokenize{evaluation:improvements-on-presentation}}
Firstly, the loading of individual forecasts requires some improvement. At this moment the data loading is slow due to an interface issue between python and the Snowflake database.
This issue has the highest priority, since grid planners do not want to wait for results.

Secondly, The current dashboard needs to be deployed within the Enexis landscape.

Additionally, some aesthetic improvements are welcome, since the presentation is quiet basic at this moment.


\chapter{Deployment}
\label{\detokenize{deployment:deployment}}\label{\detokenize{deployment::doc}}

\section{Current Status}
\label{\detokenize{deployment:current-status}}

\subsection{Code Standards}
\label{\detokenize{deployment:code-standards}}
The python project is structured simulary as \sphinxhref{https://github.com/cookiecutter/cookiecutter}{Cookiecutter}.

The code has been validated with linting by \sphinxhref{https://github.com/psf/black}{Black}, \sphinxhref{https://github.com/PyCQA/Isort}{isort}, and \sphinxhref{https://github.com/PyCQA/flake8}{Flake8}.

Unit tests have not been written yet.


\subsection{Environment}
\label{\detokenize{deployment:environment}}
The project currently uses data from the Production environment, since there is no DALI (meta)data available on the Test or Acceptance environments.

Therefore, the further implementation of the CICD pipeline is postponed for now.
(Also since within Enexis Gitlab is used, but for this study project a parallel Github repository is used.)


\subsection{Security}
\label{\detokenize{deployment:security}}
Within the Enexis domain one logs on to an environment (in this case Production).

Credentials for accessing the Snowflake database are acquired via Vault to ensure to keep secrets secret.


\subsection{Deployability}
\label{\detokenize{deployment:deployability}}
Docker files are written for following steps:
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{process_triggered}.png}\hspace*{\fill}}
\end{quote}

The steps are triggered via an entrypoint defined in the \sphinxcode{\sphinxupquote{docker\sphinxhyphen{}compose.yml}}:
\begin{itemize}
\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{docker\sphinxhyphen{}compose run update\_extremes}}}] \leavevmode
Aggregates the 15\sphinxhyphen{}minute data into weekly minimum and maximum values per DALI\sphinxhyphen{}box.
Only updates new data since the last run.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{docker\sphinxhyphen{}compose run make\_forecasts}}}] \leavevmode
Creates a tuned model for a DALI box with (high) enough measurements and makes a forecast with it.
Currently, the results are stored all with the \sphinxcode{\sphinxupquote{is\_valid}} column on \sphinxcode{\sphinxupquote{True}}.
An extra run should be done to set this column to \sphinxcode{\sphinxupquote{False}} for old forecast.
Until then, one should empty the table on beforehand.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{docker\sphinxhyphen{}compose run \sphinxhyphen{}p 8000:8000 dashboard}}}] \leavevmode
Will run the dashboard and expose it to port 8000.

\end{description}

\end{itemize}


\section{Deployment Plan}
\label{\detokenize{deployment:deployment-plan}}
The following technical actions are required for full deployment:
\begin{itemize}
\item {} 
(Meta)data for a few DALI boxes is required on the Test and Acceptance environments.

\item {} 
The project will need an app number for to trace the costs.

\item {} 
The Gitlab CICD pipeline has to be configured.

\item {} 
The project needs to land in the Artifactory repository manager of Enexis.

\item {} 
Airflow DAGs have to be configured to trigger the jobs.

\end{itemize}

The end\sphinxhyphen{}users will eventually have to accept the product to go into Production.
For that several end\sphinxhyphen{}user/stakeholder meetings are required to get valuable feedback and fine tune the product.
During these meetings the project will be assessed on the success criteria.

Usage monitoring of the tool has not been implemented, is important after deployment for value evaluation and life cycle management.


\section{Monitoring and Maintenance Plan}
\label{\detokenize{deployment:monitoring-and-maintenance-plan}}
Monitoring of the triggered jobs will be done by connecting the Airflow job to a MS Team webhook.
This automatically informs the Data Science Team if a scheduled job has failed.

The issue of model drift is obsolete, since every forecast is based on a newly trained model.

Monitoring of usage has to be implemented as mentioned above.


\section{Final Report}
\label{\detokenize{deployment:final-report}}
One can create a pdf version of this documentation by the following steps:
\begin{itemize}
\item {} 
Clone the repository.

\item {} 
Run \sphinxcode{\sphinxupquote{make latexpdf}}

\end{itemize}


\section{Project review}
\label{\detokenize{deployment:project-review}}
This section covers my personal growth reflection on the Lead track of JADS.

Firstly, I will cover the objectives and criteria set by JADS.

Secondly, I will review my personal goals.


\subsection{JADS \sphinxhyphen{} Professional Education \sphinxhyphen{} Lead Track}
\label{\detokenize{deployment:jads-professional-education-lead-track}}

\subsubsection{Learning Objectives}
\label{\detokenize{deployment:learning-objectives}}
The general learning objectives for the Professional Education Lead track of JADS are:
\begin{itemize}
\item {} \begin{description}
\item[{Acquiring the knowledge and skills covered in the courses (technical and non\sphinxhyphen{}technical).}] \leavevmode
The most valuable courses were the non\sphinxhyphen{}technical ones.
Partially, because there was maybe more to gain for me as a more technical character.
But mainly, since they inspired me and enabled me to accept to embrace that skill set and also provided me with concrete tips to put it into practice.

Some technical lectures (e.g. “from POCs to Production” and “A Primer in Data Engineering”) confirmed that the way of working and view on data science within my professional team is on the right track.
Other technical courses (e.g. “Bayesian Nets”, “Recent Advances in A.I.”) inspired me and sparked an interest in new subjects.
Those subjects are now on my personal bucket list for a technical deep dive in the near future.
\begin{description}
\item[{Concluding: I am convinced the courses in the Lead Track moved a good number of my skills towards the conscious incompetence and conscious competence levels.}] \leavevmode
\noindent{\hspace*{\fill}\sphinxincludegraphics[width=800\sphinxpxdimen]{{competence}.png}\hspace*{\fill}}

\end{description}

The Conscious Competence Learning Model (source: \sphinxhref{http://www.pamelaslim.com}{pamelaslim.com}).

\end{description}

\item {} \begin{description}
\item[{Leading and implementing an impactful data science project by use of the CRISP\sphinxhyphen{}DM process.}] \leavevmode
The described project of this documentation shows the result of that.

\end{description}

\item {} \begin{description}
\item[{Forming individuals to enable them to make impact with data science.}] \leavevmode
The coaching from the educators of JADS helped me reassess my future career.
\begin{itemize}
\item {} 
The discussions with Jeroen about academic and engineering skills helped me appreciating my skills, my work and myself more.

\item {} 
The coaching of Kyril helped me to form a clearer view on my career goal and how to get there.

\item {} 
The highly effective presentation masterclass of Raoul helped me to reach goals more effective.

\end{itemize}

\end{description}

\end{itemize}


\subsubsection{Evaluation Criteria}
\label{\detokenize{deployment:evaluation-criteria}}
The evaluation criteria for the Professional Education Lead track of JADS and how I translated them are:
\begin{itemize}
\item {} 
Business Value
\begin{itemize}
\item {} 
Use case selection

\item {} 
Stakeholder analysis

\item {} 
Stakeholder and expectation management

\item {} 
Value flow down diagram

\item {} 
Regular business review moments

\end{itemize}

\item {} 
Programming
\begin{itemize}
\item {} 
Coding standards with Cookiecutter and linting (black, isort, flake8)

\item {} 
Using Sphinx for auto API documentation in GitHub

\item {} 
Interactive visualisations in Altair

\item {} 
Dashboard in Panel

\end{itemize}

\item {} 
Data engineering
\begin{itemize}
\item {} 
Snowflake database preprocessing usage (asynchronous queries, ETL)

\item {} 
Vault credential management

\item {} 
Docker (compose with entrypoint) for every process step

\end{itemize}

\item {} 
Data analytics \& machine learning
\begin{itemize}
\item {} 
Coding data management and model from scratch (since not using sklearn)

\item {} 
Probabilistic modelling in PyMC3

\item {} 
Using Fourier and Taylor series in generalized additive model for time series forecast

\end{itemize}

\item {} 
Professional standard of reporting
\begin{itemize}
\item {} 
Using Sphinx for this documentation

\item {} 
Status slide deck after sprint review with end users

\item {} 
Project status / pitch and management summary for JADS peers and training

\end{itemize}

\item {} 
Academic / research skills
\begin{itemize}
\item {} 
Using the engineering approach (instead of the scientific method or the axiomatic system) to iteratively create and validate model and outcome.

\end{itemize}

\end{itemize}


\subsubsection{Personal Goals}
\label{\detokenize{deployment:personal-goals}}
Additionally, there were also my personal learning objectives:
\begin{itemize}
\item {} 
Going through all the steps of CRISP\sphinxhyphen{}DM by myself (from Business Understanding to Deployment).

\item {} 
Better understanding of probabilistic modeling techniques (e.g. bayesian models, probabilistic tools).

\item {} 
Able to value my data skills and knowledge and creating traction / more confidence on flourishing as a data scientist.

\end{itemize}

One by one my personal learning objectives are fulfilled.

However, my conscious incompetence skill set has grown dramatically.
So my new learning objectives are already there. (I will just have to order that backlog.)


\paragraph{To the persistent reader}
\label{\detokenize{deployment:to-the-persistent-reader}}
This project is named Spark within Enexis.

But it has not just solely been named after the developer: \sphinxhref{https://en.wiktionary.org/wiki/sp\%C3\%A1}{Spa}


\chapter{API Reference}
\label{\detokenize{autoapi/index:api-reference}}\label{\detokenize{autoapi/index::doc}}
This page contains auto\sphinxhyphen{}generated API reference documentation %
\begin{footnote}[1]\sphinxAtStartFootnote
Created with \sphinxhref{https://github.com/readthedocs/sphinx-autoapi}{sphinx\sphinxhyphen{}autoapi}
%
\end{footnote}.


\section{\sphinxstyleliteralintitle{\sphinxupquote{src}}}
\label{\detokenize{autoapi/src/index:module-src}}\label{\detokenize{autoapi/src/index:src}}\label{\detokenize{autoapi/src/index::doc}}\index{module@\spxentry{module}!src@\spxentry{src}}\index{src@\spxentry{src}!module@\spxentry{module}}

\subsection{Subpackages}
\label{\detokenize{autoapi/src/index:subpackages}}

\subsubsection{\sphinxstyleliteralintitle{\sphinxupquote{src.forecast}}}
\label{\detokenize{autoapi/src/forecast/index:module-src.forecast}}\label{\detokenize{autoapi/src/forecast/index:src-forecast}}\label{\detokenize{autoapi/src/forecast/index::doc}}\index{module@\spxentry{module}!src.forecast@\spxentry{src.forecast}}\index{src.forecast@\spxentry{src.forecast}!module@\spxentry{module}}

\paragraph{Submodules}
\label{\detokenize{autoapi/src/forecast/index:submodules}}

\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.forecast.assess}}}
\label{\detokenize{autoapi/src/forecast/assess/index:module-src.forecast.assess}}\label{\detokenize{autoapi/src/forecast/assess/index:src-forecast-assess}}\label{\detokenize{autoapi/src/forecast/assess/index::doc}}\index{module@\spxentry{module}!src.forecast.assess@\spxentry{src.forecast.assess}}\index{src.forecast.assess@\spxentry{src.forecast.assess}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/forecast/assess/index:module-contents}}\index{logger (in module src.forecast.assess)@\spxentry{logger}\spxextra{in module src.forecast.assess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/forecast/assess/index:src.forecast.assess.logger}}\pysigline{\sphinxcode{\sphinxupquote{src.forecast.assess.}}\sphinxbfcode{\sphinxupquote{logger}}}
\end{fulllineitems}

\index{asses\_forecasts() (in module src.forecast.assess)@\spxentry{asses\_forecasts()}\spxextra{in module src.forecast.assess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/forecast/assess/index:src.forecast.assess.asses_forecasts}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.forecast.assess.}}\sphinxbfcode{\sphinxupquote{asses\_forecasts}}}{\emph{\DUrole{n}{df\_total}}, \emph{\DUrole{n}{df\_meta}}}{}
Assesses if and when a transformer will overload based on the forecasts and metadata.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_total: pd.DataFrame}}] \leavevmode
DataFrame with forecasts.

\item[{\sphinxstylestrong{df\_meta: pd.DataFrame}}] \leavevmode
DataFrame with metadata of the transformer.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
Result of the assessment.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.forecast.forecast}}}
\label{\detokenize{autoapi/src/forecast/forecast/index:module-src.forecast.forecast}}\label{\detokenize{autoapi/src/forecast/forecast/index:src-forecast-forecast}}\label{\detokenize{autoapi/src/forecast/forecast/index::doc}}\index{module@\spxentry{module}!src.forecast.forecast@\spxentry{src.forecast.forecast}}\index{src.forecast.forecast@\spxentry{src.forecast.forecast}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/forecast/forecast/index:module-contents}}\index{logger (in module src.forecast.forecast)@\spxentry{logger}\spxextra{in module src.forecast.forecast}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/forecast/forecast/index:src.forecast.forecast.logger}}\pysigline{\sphinxcode{\sphinxupquote{src.forecast.forecast.}}\sphinxbfcode{\sphinxupquote{logger}}}
\end{fulllineitems}

\index{config (in module src.forecast.forecast)@\spxentry{config}\spxextra{in module src.forecast.forecast}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/forecast/forecast/index:src.forecast.forecast.config}}\pysigline{\sphinxcode{\sphinxupquote{src.forecast.forecast.}}\sphinxbfcode{\sphinxupquote{config}}}
\end{fulllineitems}

\index{determine\_estimates() (in module src.forecast.forecast)@\spxentry{determine\_estimates()}\spxextra{in module src.forecast.forecast}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/forecast/forecast/index:src.forecast.forecast.determine_estimates}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.forecast.forecast.}}\sphinxbfcode{\sphinxupquote{determine\_estimates}}}{\emph{\DUrole{n}{df\_observed}}}{}
Determine model parameters and forecast for a extreme (max or min).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_observed}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
observed values of DALI data

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
estimates for extreme

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{determine\_estimates\_minmax() (in module src.forecast.forecast)@\spxentry{determine\_estimates\_minmax()}\spxextra{in module src.forecast.forecast}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/forecast/forecast/index:src.forecast.forecast.determine_estimates_minmax}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.forecast.forecast.}}\sphinxbfcode{\sphinxupquote{determine\_estimates\_minmax}}}{\emph{\DUrole{n}{df\_observed}}}{}
Determine model parameters and forecast for a extreme (max or min).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_observed}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
observed values of DALI data

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
estimates for min and max

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{forecast() (in module src.forecast.forecast)@\spxentry{forecast()}\spxextra{in module src.forecast.forecast}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/forecast/forecast/index:src.forecast.forecast.forecast}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.forecast.forecast.}}\sphinxbfcode{\sphinxupquote{forecast}}}{\emph{\DUrole{n}{boxid}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Forecast for one or more DALI boxes.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{boxid}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#list}{\sphinxcode{\sphinxupquote{list}}}{]}
string or list with boxids to forecast for.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
DataFrame with observations and forecast on long format

\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.forecast.make\_forecasts}}}
\label{\detokenize{autoapi/src/forecast/make_forecasts/index:module-src.forecast.make_forecasts}}\label{\detokenize{autoapi/src/forecast/make_forecasts/index:src-forecast-make-forecasts}}\label{\detokenize{autoapi/src/forecast/make_forecasts/index::doc}}\index{module@\spxentry{module}!src.forecast.make\_forecasts@\spxentry{src.forecast.make\_forecasts}}\index{src.forecast.make\_forecasts@\spxentry{src.forecast.make\_forecasts}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/forecast/make_forecasts/index:module-contents}}\index{logger (in module src.forecast.make\_forecasts)@\spxentry{logger}\spxextra{in module src.forecast.make\_forecasts}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/forecast/make_forecasts/index:src.forecast.make_forecasts.logger}}\pysigline{\sphinxcode{\sphinxupquote{src.forecast.make\_forecasts.}}\sphinxbfcode{\sphinxupquote{logger}}}
\end{fulllineitems}

\index{make\_forecasts() (in module src.forecast.make\_forecasts)@\spxentry{make\_forecasts()}\spxextra{in module src.forecast.make\_forecasts}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/forecast/make_forecasts/index:src.forecast.make_forecasts.make_forecasts}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.forecast.make\_forecasts.}}\sphinxbfcode{\sphinxupquote{make\_forecasts}}}{\emph{\DUrole{n}{clear}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Make forecasts for all boxes.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{clear: bool}}] \leavevmode
Clear the Snowflake table

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/constants.html\#None}{\sphinxcode{\sphinxupquote{None}}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{\sphinxstyleliteralintitle{\sphinxupquote{src.model}}}
\label{\detokenize{autoapi/src/model/index:module-src.model}}\label{\detokenize{autoapi/src/model/index:src-model}}\label{\detokenize{autoapi/src/model/index::doc}}\index{module@\spxentry{module}!src.model@\spxentry{src.model}}\index{src.model@\spxentry{src.model}!module@\spxentry{module}}

\paragraph{Submodules}
\label{\detokenize{autoapi/src/model/index:submodules}}

\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.model.format}}}
\label{\detokenize{autoapi/src/model/format/index:module-src.model.format}}\label{\detokenize{autoapi/src/model/format/index:src-model-format}}\label{\detokenize{autoapi/src/model/format/index::doc}}\index{module@\spxentry{module}!src.model.format@\spxentry{src.model.format}}\index{src.model.format@\spxentry{src.model.format}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/model/format/index:module-contents}}\index{logger (in module src.model.format)@\spxentry{logger}\spxextra{in module src.model.format}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/model/format/index:src.model.format.logger}}\pysigline{\sphinxcode{\sphinxupquote{src.model.format.}}\sphinxbfcode{\sphinxupquote{logger}}}
\end{fulllineitems}

\index{make\_quantile\_bands() (in module src.model.format)@\spxentry{make\_quantile\_bands()}\spxextra{in module src.model.format}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/model/format/index:src.model.format.make_quantile_bands}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.model.format.}}\sphinxbfcode{\sphinxupquote{make\_quantile\_bands}}}{\emph{\DUrole{n}{df\_base}}, \emph{\DUrole{n}{samples}}, \emph{\DUrole{n}{quantiles}\DUrole{o}{=}\DUrole{default_value}{5, 15, 50, 85, 95}}}{}
Translate samples to bands with edges defined by the given quantiles and merge them to a base DataFrame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_base}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
base DataFrame with timestamps/length in accordance of the samples shape

\item[{\sphinxstylestrong{samples}}] \leavevmode{[}\sphinxcode{\sphinxupquote{np.array}}{]}
the posterior predictive samples

\item[{\sphinxstylestrong{quantiles: list}}] \leavevmode
an iterable with the edges of the bands (0,1), ordered increasingly.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
long format version with the quantile bands of the samples

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{format\_model\_estimates() (in module src.model.format)@\spxentry{format\_model\_estimates()}\spxextra{in module src.model.format}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/model/format/index:src.model.format.format_model_estimates}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.model.format.}}\sphinxbfcode{\sphinxupquote{format\_model\_estimates}}}{\emph{\DUrole{n}{df\_base}}, \emph{\DUrole{n}{pp}}, \emph{\DUrole{n}{quantiles}\DUrole{o}{=}\DUrole{default_value}{5, 15, 50, 85, 95}}}{}
Format the samples into quantile bands for every model variable.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_base}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
base DataFrame with timestamps/length in accordance of the samples shape

\item[{\sphinxstylestrong{pp}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#dict}{\sphinxcode{\sphinxupquote{dict}}}{]}
per model variable (key) the posterior predictive samples

\item[{\sphinxstylestrong{quantiles: list}}] \leavevmode
an iterable with the edges of the bands (0,1), ordered increasingly.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
long format version with the quantile bands of the samples for every model variable

\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.model.model}}}
\label{\detokenize{autoapi/src/model/model/index:module-src.model.model}}\label{\detokenize{autoapi/src/model/model/index:src-model-model}}\label{\detokenize{autoapi/src/model/model/index::doc}}\index{module@\spxentry{module}!src.model.model@\spxentry{src.model.model}}\index{src.model.model@\spxentry{src.model.model}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/model/model/index:module-contents}}\index{logger (in module src.model.model)@\spxentry{logger}\spxextra{in module src.model.model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/model/model/index:src.model.model.logger}}\pysigline{\sphinxcode{\sphinxupquote{src.model.model.}}\sphinxbfcode{\sphinxupquote{logger}}}
\end{fulllineitems}

\index{det\_dot() (in module src.model.model)@\spxentry{det\_dot()}\spxextra{in module src.model.model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/model/model/index:src.model.model.det_dot}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.model.model.}}\sphinxbfcode{\sphinxupquote{det\_dot}}}{\emph{\DUrole{n}{a}}, \emph{\DUrole{n}{b}}}{}
Dot product for Theano.

The theano dot product and NUTS sampler don’t work with large matrices.
Copyright (c) 2021. Ritchie Vink
source: \sphinxurl{https://www.ritchievink.com/blog/2018/10/09/} …
build\sphinxhyphen{}facebooks\sphinxhyphen{}prophet\sphinxhyphen{}in\sphinxhyphen{}pymc3\sphinxhyphen{}bayesian\sphinxhyphen{}time\sphinxhyphen{}series\sphinxhyphen{}analyis\sphinxhyphen{}with\sphinxhyphen{}generalized\sphinxhyphen{}additive\sphinxhyphen{}models/
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{a}}] \leavevmode{[}\sphinxcode{\sphinxupquote{np.array}}{]}
\item[{\sphinxstylestrong{b}}] \leavevmode{[}\sphinxcode{\sphinxupquote{tt.vector}}{]}
\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{np.array}}}] \leavevmode
dot product of the two.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{fourier\_series() (in module src.model.model)@\spxentry{fourier\_series()}\spxextra{in module src.model.model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/model/model/index:src.model.model.fourier_series}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.model.model.}}\sphinxbfcode{\sphinxupquote{fourier\_series}}}{\emph{\DUrole{n}{t}}, \emph{\DUrole{n}{p}\DUrole{o}{=}\DUrole{default_value}{52.1775}}, \emph{\DUrole{n}{n}\DUrole{o}{=}\DUrole{default_value}{5}}}{}
Calculate fourier representation of t for a period and order.

Copyright (c) 2021. Ritchie Vink
Based on source: \sphinxurl{https://www.ritchievink.com/blog/2018/10/09/} …
build\sphinxhyphen{}facebooks\sphinxhyphen{}prophet\sphinxhyphen{}in\sphinxhyphen{}pymc3\sphinxhyphen{}bayesian\sphinxhyphen{}time\sphinxhyphen{}series\sphinxhyphen{}analyis\sphinxhyphen{}with\sphinxhyphen{}generalized\sphinxhyphen{}additive\sphinxhyphen{}models/
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{t}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#range}{\sphinxcode{\sphinxupquote{range}}}{]}
range to be used as input variable

\item[{\sphinxstylestrong{p}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/functions.html\#float}{\sphinxcode{\sphinxupquote{float}}}{]}
period to use for the fourier orders

\item[{\sphinxstylestrong{n}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/functions.html\#int}{\sphinxcode{\sphinxupquote{int}}}{]}
order of fourier series

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{np.array}}}] \leavevmode
matrix fourier representation of t

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{seasonality\_model() (in module src.model.model)@\spxentry{seasonality\_model()}\spxextra{in module src.model.model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/model/model/index:src.model.model.seasonality_model}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.model.model.}}\sphinxbfcode{\sphinxupquote{seasonality\_model}}}{\emph{\DUrole{n}{t}}, \emph{\DUrole{n}{p}\DUrole{o}{=}\DUrole{default_value}{52.1775}}, \emph{\DUrole{n}{n}\DUrole{o}{=}\DUrole{default_value}{5}}, \emph{\DUrole{n}{seasonality\_prior\_scale}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Create seasonality model with fourier series.

Copyright (c) 2021. Ritchie Vink
Based on source: \sphinxurl{https://www.ritchievink.com/blog/2018/10/09/} …
build\sphinxhyphen{}facebooks\sphinxhyphen{}prophet\sphinxhyphen{}in\sphinxhyphen{}pymc3\sphinxhyphen{}bayesian\sphinxhyphen{}time\sphinxhyphen{}series\sphinxhyphen{}analyis\sphinxhyphen{}with\sphinxhyphen{}generalized\sphinxhyphen{}additive\sphinxhyphen{}models/
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{t}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#range}{\sphinxcode{\sphinxupquote{range}}}{]}
range to be used as input variable

\item[{\sphinxstylestrong{p}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/functions.html\#float}{\sphinxcode{\sphinxupquote{float}}}{]}
period to use for the fourier orders

\item[{\sphinxstylestrong{n}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/functions.html\#int}{\sphinxcode{\sphinxupquote{int}}}{]}
order of fourier series

\item[{\sphinxstylestrong{seasonality\_prior\_scale: float}}] \leavevmode
\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pm.var}}}] \leavevmode
PYMC3 variable

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{polynomial() (in module src.model.model)@\spxentry{polynomial()}\spxextra{in module src.model.model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/model/model/index:src.model.model.polynomial}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.model.model.}}\sphinxbfcode{\sphinxupquote{polynomial}}}{\emph{\DUrole{n}{t}}, \emph{\DUrole{n}{n}\DUrole{o}{=}\DUrole{default_value}{4}}}{}
Calculate polynomial representation of t for an order.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{t}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#range}{\sphinxcode{\sphinxupquote{range}}}{]}
range to be used as input variable

\item[{\sphinxstylestrong{n}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/functions.html\#int}{\sphinxcode{\sphinxupquote{int}}}{]}
order of polynomial

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{np.array}}}] \leavevmode
matrix polynomial representation of t

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{drift\_model() (in module src.model.model)@\spxentry{drift\_model()}\spxextra{in module src.model.model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/model/model/index:src.model.model.drift_model}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.model.model.}}\sphinxbfcode{\sphinxupquote{drift\_model}}}{\emph{\DUrole{n}{t}}, \emph{\DUrole{n}{n}\DUrole{o}{=}\DUrole{default_value}{4}}}{}
Polynomal drift/trend function for additive model.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{t}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#range}{\sphinxcode{\sphinxupquote{range}}}{]}
range to be used as input variable

\item[{\sphinxstylestrong{n}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/functions.html\#int}{\sphinxcode{\sphinxupquote{int}}}{]}
order of polynomal.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pm.var}}}] \leavevmode
PYMC3 variable

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_model() (in module src.model.model)@\spxentry{create\_model()}\spxextra{in module src.model.model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/model/model/index:src.model.model.create_model}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.model.model.}}\sphinxbfcode{\sphinxupquote{create\_model}}}{\emph{\DUrole{n}{t}}, \emph{\DUrole{n}{y}}, \emph{\DUrole{n}{p\_fourier}}, \emph{\DUrole{n}{n\_fourier}\DUrole{o}{=}\DUrole{default_value}{5}}, \emph{\DUrole{n}{n\_polynomial}\DUrole{o}{=}\DUrole{default_value}{2}}}{}
Create a PYMC3 GAM model with a trend/drift and a seasonal/yearly component.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{t}}] \leavevmode{[}\sphinxcode{\sphinxupquote{timestamps}}{]}
input series of scaled timestamps

\item[{\sphinxstylestrong{y}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/functions.html\#float}{\sphinxcode{\sphinxupquote{float}}}{]}
observed values

\item[{\sphinxstylestrong{p\_fourier: float}}] \leavevmode
scaled period of the timestamps to take for the fourier component (a year)

\item[{\sphinxstylestrong{n\_fourier}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/functions.html\#int}{\sphinxcode{\sphinxupquote{int}}}{]}
order of the fourier component

\item[{\sphinxstylestrong{n\_polynomial: inbt}}] \leavevmode
order of the polynomial component

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{PYMC3}} \sphinxcode{\sphinxupquote{model}} \sphinxcode{\sphinxupquote{context}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{\sphinxstyleliteralintitle{\sphinxupquote{src.plot}}}
\label{\detokenize{autoapi/src/plot/index:module-src.plot}}\label{\detokenize{autoapi/src/plot/index:src-plot}}\label{\detokenize{autoapi/src/plot/index::doc}}\index{module@\spxentry{module}!src.plot@\spxentry{src.plot}}\index{src.plot@\spxentry{src.plot}!module@\spxentry{module}}

\paragraph{Submodules}
\label{\detokenize{autoapi/src/plot/index:submodules}}

\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.plot.altair}}}
\label{\detokenize{autoapi/src/plot/altair/index:module-src.plot.altair}}\label{\detokenize{autoapi/src/plot/altair/index:src-plot-altair}}\label{\detokenize{autoapi/src/plot/altair/index::doc}}\index{module@\spxentry{module}!src.plot.altair@\spxentry{src.plot.altair}}\index{src.plot.altair@\spxentry{src.plot.altair}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/plot/altair/index:module-contents}}\index{plot\_estimate() (in module src.plot.altair)@\spxentry{plot\_estimate()}\spxextra{in module src.plot.altair}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/altair/index:src.plot.altair.plot_estimate}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.altair.}}\sphinxbfcode{\sphinxupquote{plot\_estimate}}}{\emph{\DUrole{n}{df}}, \emph{\DUrole{n}{legend}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
Plot the load forecast transformer.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
DataFrame with the columns date, lower, upper, forecast(Q10\sphinxhyphen{}Q190, median), extreme

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{Altair}} \sphinxcode{\sphinxupquote{chart}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_observed() (in module src.plot.altair)@\spxentry{plot\_observed()}\spxextra{in module src.plot.altair}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/altair/index:src.plot.altair.plot_observed}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.altair.}}\sphinxbfcode{\sphinxupquote{plot\_observed}}}{\emph{\DUrole{n}{df}}}{}
Plot the historic/observed load of a transformer.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
DataFrame with like:

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{Altair}} \sphinxcode{\sphinxupquote{chart}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_limits() (in module src.plot.altair)@\spxentry{plot\_limits()}\spxextra{in module src.plot.altair}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/altair/index:src.plot.altair.plot_limits}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.altair.}}\sphinxbfcode{\sphinxupquote{plot\_limits}}}{\emph{\DUrole{n}{df}}}{}
Plot the capacity limits of a transformer as a ruler of as a line if metadata changes over time.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
DataFrame with the limits to be plotted

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{Altair}} \sphinxcode{\sphinxupquote{chart}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{lightness\_scale() (in module src.plot.altair)@\spxentry{lightness\_scale()}\spxextra{in module src.plot.altair}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/altair/index:src.plot.altair.lightness_scale}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.altair.}}\sphinxbfcode{\sphinxupquote{lightness\_scale}}}{\emph{\DUrole{n}{factor}}, \emph{\DUrole{n}{limits}\DUrole{o}{=}\DUrole{default_value}{{[}'\#bedef4', '\#1f77b4'{]}}}}{}
Create right color intensity for float values.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{factor: float}}] \leavevmode
Factor of full color intensity.

\item[{\sphinxstylestrong{limits: list}}] \leavevmode
Hex colour codes for start and end of scale.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#str}{\sphinxcode{\sphinxupquote{str}}}}] \leavevmode
Hex code for the factor value.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_base() (in module src.plot.altair)@\spxentry{plot\_base()}\spxextra{in module src.plot.altair}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/altair/index:src.plot.altair.plot_base}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.altair.}}\sphinxbfcode{\sphinxupquote{plot\_base}}}{\emph{\DUrole{n}{df\_data}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{df\_meta}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Plot one or more of the following: history, forecast, transformer limits.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_data}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
DataFrame with the timeseries

\item[{\sphinxstylestrong{df\_meta}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
DataFrame with the metadata

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{Altair}} \sphinxcode{\sphinxupquote{layer}} \sphinxcode{\sphinxupquote{chart}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_decompose() (in module src.plot.altair)@\spxentry{plot\_decompose()}\spxextra{in module src.plot.altair}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/altair/index:src.plot.altair.plot_decompose}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.altair.}}\sphinxbfcode{\sphinxupquote{plot\_decompose}}}{\emph{\DUrole{n}{df}}}{}
Plot decomposition of PYMC3 GAM model components by model variable.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
Data of estimates in long format.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{alt.Chart}}}] \leavevmode
Altair plot.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_all() (in module src.plot.altair)@\spxentry{plot\_all()}\spxextra{in module src.plot.altair}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/altair/index:src.plot.altair.plot_all}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.altair.}}\sphinxbfcode{\sphinxupquote{plot\_all}}}{\emph{\DUrole{n}{df\_data}}, \emph{\DUrole{n}{df\_meta}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Plot estimates, observed and limits.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_data}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
DataFrame with the timeseries

\item[{\sphinxstylestrong{df\_meta}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
DataFrame with the metadata

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{Altair}} \sphinxcode{\sphinxupquote{layer}} \sphinxcode{\sphinxupquote{chart}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.plot.dashboard}}}
\label{\detokenize{autoapi/src/plot/dashboard/index:module-src.plot.dashboard}}\label{\detokenize{autoapi/src/plot/dashboard/index:src-plot-dashboard}}\label{\detokenize{autoapi/src/plot/dashboard/index::doc}}\index{module@\spxentry{module}!src.plot.dashboard@\spxentry{src.plot.dashboard}}\index{src.plot.dashboard@\spxentry{src.plot.dashboard}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/plot/dashboard/index:module-contents}}\index{build\_dashboard() (in module src.plot.dashboard)@\spxentry{build\_dashboard()}\spxextra{in module src.plot.dashboard}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/dashboard/index:src.plot.dashboard.build_dashboard}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.dashboard.}}\sphinxbfcode{\sphinxupquote{build\_dashboard}}}{}{}
Initialize dashboard.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/constants.html\#None}{\sphinxcode{\sphinxupquote{None}}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{dashboard (in module src.plot.dashboard)@\spxentry{dashboard}\spxextra{in module src.plot.dashboard}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/dashboard/index:src.plot.dashboard.dashboard}}\pysigline{\sphinxcode{\sphinxupquote{src.plot.dashboard.}}\sphinxbfcode{\sphinxupquote{dashboard}}}
\end{fulllineitems}

\index{dashboard (in module src.plot.dashboard)@\spxentry{dashboard}\spxextra{in module src.plot.dashboard}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/dashboard/index:id0}}\pysigline{\sphinxcode{\sphinxupquote{src.plot.dashboard.}}\sphinxbfcode{\sphinxupquote{dashboard}}}
\end{fulllineitems}



\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.plot.format}}}
\label{\detokenize{autoapi/src/plot/format/index:module-src.plot.format}}\label{\detokenize{autoapi/src/plot/format/index:src-plot-format}}\label{\detokenize{autoapi/src/plot/format/index::doc}}\index{module@\spxentry{module}!src.plot.format@\spxentry{src.plot.format}}\index{src.plot.format@\spxentry{src.plot.format}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/plot/format/index:module-contents}}\index{format\_limits() (in module src.plot.format)@\spxentry{format\_limits()}\spxextra{in module src.plot.format}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/format/index:src.plot.format.format_limits}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.format.}}\sphinxbfcode{\sphinxupquote{format\_limits}}}{\emph{\DUrole{n}{df\_meta}}, \emph{\DUrole{n}{df\_data}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Format the transformer limits for plotting.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_meta: pd.DataFrame}}] \leavevmode
DataFrame with the trasnformer limits.

\item[{\sphinxstylestrong{df\_data: pd.DataFrame}}] \leavevmode
Optionally, the historic preprocess to determine the time range for the limits.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{A}} \sphinxcode{\sphinxupquote{DataFrame}} \sphinxcode{\sphinxupquote{with}} \sphinxcode{\sphinxupquote{the}} \sphinxcode{\sphinxupquote{limits}} \sphinxcode{\sphinxupquote{to}} plot.}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{format\_history() (in module src.plot.format)@\spxentry{format\_history()}\spxextra{in module src.plot.format}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/format/index:src.plot.format.format_history}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.format.}}\sphinxbfcode{\sphinxupquote{format\_history}}}{\emph{\DUrole{n}{df\_data}}}{}
Format the historic for plotting.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_data: pd.DataFrame}}] \leavevmode
The historic preprocess to be plotted.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{A}} \sphinxcode{\sphinxupquote{DataFrame}} \sphinxcode{\sphinxupquote{with}} \sphinxcode{\sphinxupquote{the}} \sphinxcode{\sphinxupquote{historic}} \sphinxcode{\sphinxupquote{preprocess}} \sphinxcode{\sphinxupquote{to}} plot.}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{format\_forecast() (in module src.plot.format)@\spxentry{format\_forecast()}\spxextra{in module src.plot.format}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/format/index:src.plot.format.format_forecast}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.format.}}\sphinxbfcode{\sphinxupquote{format\_forecast}}}{\emph{\DUrole{n}{df\_forecast}}}{}
Format the forecasted load.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df: pd.DataFrame}}] \leavevmode
\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pass}} \sphinxcode{\sphinxupquote{through}} \sphinxhref{https://docs.python.org/3/library/functions.html\#input}{\sphinxcode{\sphinxupquote{input}}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{dummy\_forecast() (in module src.plot.format)@\spxentry{dummy\_forecast()}\spxextra{in module src.plot.format}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/plot/format/index:src.plot.format.dummy_forecast}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.plot.format.}}\sphinxbfcode{\sphinxupquote{dummy\_forecast}}}{\emph{\DUrole{n}{df}}}{}
Create a dummy forecast with median and Q10\sphinxhyphen{}Q90 based on historic preprocess to test plotting function.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
Historic preprocess to use as a basis

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
Forecast preprocess that can be used to plot with plot\_forecast()

\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{\sphinxstyleliteralintitle{\sphinxupquote{src.preprocess}}}
\label{\detokenize{autoapi/src/preprocess/index:module-src.preprocess}}\label{\detokenize{autoapi/src/preprocess/index:src-preprocess}}\label{\detokenize{autoapi/src/preprocess/index::doc}}\index{module@\spxentry{module}!src.preprocess@\spxentry{src.preprocess}}\index{src.preprocess@\spxentry{src.preprocess}!module@\spxentry{module}}

\paragraph{Submodules}
\label{\detokenize{autoapi/src/preprocess/index:submodules}}

\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.preprocess.preprocess}}}
\label{\detokenize{autoapi/src/preprocess/preprocess/index:module-src.preprocess.preprocess}}\label{\detokenize{autoapi/src/preprocess/preprocess/index:src-preprocess-preprocess}}\label{\detokenize{autoapi/src/preprocess/preprocess/index::doc}}\index{module@\spxentry{module}!src.preprocess.preprocess@\spxentry{src.preprocess.preprocess}}\index{src.preprocess.preprocess@\spxentry{src.preprocess.preprocess}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/preprocess/preprocess/index:module-contents}}\index{logger (in module src.preprocess.preprocess)@\spxentry{logger}\spxextra{in module src.preprocess.preprocess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.logger}}\pysigline{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.}}\sphinxbfcode{\sphinxupquote{logger}}}
\end{fulllineitems}

\index{too\_short() (in module src.preprocess.preprocess)@\spxentry{too\_short()}\spxextra{in module src.preprocess.preprocess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.too_short}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.}}\sphinxbfcode{\sphinxupquote{too\_short}}}{\emph{\DUrole{n}{df\_data}}, \emph{\DUrole{n}{threshold}\DUrole{o}{=}\DUrole{default_value}{52}}}{}
Check if number of entries is long enough.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_data: pd.DataFrame}}] \leavevmode
Data to check.

\item[{\sphinxstylestrong{threshold: int}}] \leavevmode
Minimum lenght.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#bltin-boolean-values}{\DUrole{xref,std,std-ref}{bool}}}] \leavevmode
True if preprocess is long enough.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{too\_small() (in module src.preprocess.preprocess)@\spxentry{too\_small()}\spxextra{in module src.preprocess.preprocess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.too_small}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.}}\sphinxbfcode{\sphinxupquote{too\_small}}}{\emph{\DUrole{n}{df\_data}}, \emph{\DUrole{n}{capacity}}, \emph{\DUrole{n}{threshold}\DUrole{o}{=}\DUrole{default_value}{0.25}}}{}
Check if values of preprocess is greater than threshold x capacity of transformer.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_data: pd.DataFrame}}] \leavevmode
Data to check.

\item[{\sphinxstylestrong{capacity: int}}] \leavevmode
Capacity of the transformer.

\item[{\sphinxstylestrong{threshold: int}}] \leavevmode
Fraction of the capacity that should be reached.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#bltin-boolean-values}{\DUrole{xref,std,std-ref}{bool}}}] \leavevmode
True if preprocess exists that is greater than threshold x capacity.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{remove\_leading\_idling() (in module src.preprocess.preprocess)@\spxentry{remove\_leading\_idling()}\spxextra{in module src.preprocess.preprocess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.remove_leading_idling}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.}}\sphinxbfcode{\sphinxupquote{remove\_leading\_idling}}}{\emph{\DUrole{n}{df\_data}}, \emph{\DUrole{n}{capacity}}, \emph{\DUrole{n}{threshold}\DUrole{o}{=}\DUrole{default_value}{0.01}}}{}
Remove preprocess that was generated when DALI box was active but electrical connection was not.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_data}}] \leavevmode{[}\sphinxcode{\sphinxupquote{ps.DataFrame}}{]}
Data to be cleaned.

\item[{\sphinxstylestrong{capacity: int}}] \leavevmode
Capacity of the transformer.

\item[{\sphinxstylestrong{threshold: int}}] \leavevmode
Fraction of the capacity that should be reached.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
DataFrame without the idling preprocess points.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_data() (in module src.preprocess.preprocess)@\spxentry{load\_data()}\spxextra{in module src.preprocess.preprocess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.load_data}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.}}\sphinxbfcode{\sphinxupquote{load\_data}}}{\emph{\DUrole{n}{boxid}}}{}
Load preprocess and metadata for boxid and do preprocessing.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{boxid: str}}] \leavevmode
ID of DALI box.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/constants.html\#None}{\sphinxcode{\sphinxupquote{None}}} | (\sphinxcode{\sphinxupquote{df\_data}}, \sphinxcode{\sphinxupquote{df\_meta}})}] \leavevmode
If checks are OK, return DataFrames with historic and meta preprocess.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{format\_data() (in module src.preprocess.preprocess)@\spxentry{format\_data()}\spxextra{in module src.preprocess.preprocess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.format_data}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.}}\sphinxbfcode{\sphinxupquote{format\_data}}}{\emph{\DUrole{n}{df}}}{}
Format the loaded weekly data in the correct form.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df: pd.DataFrame}}] \leavevmode
Loaded weekly extremes.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
Formatted data.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{split\_last() (in module src.preprocess.preprocess)@\spxentry{split\_last()}\spxextra{in module src.preprocess.preprocess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.split_last}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.}}\sphinxbfcode{\sphinxupquote{split\_last}}}{\emph{\DUrole{n}{df\_data}}, \emph{\DUrole{n}{period}\DUrole{o}{=}\DUrole{default_value}{dt.timedelta(weeks=26)}}}{}
Split the historic dataset into a train and test set a certain period from the end.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df\_data: pd.DataFrame}}] \leavevmode
Dataset to split.

\item[{\sphinxstylestrong{period: datetime}}] \leavevmode
Period from the end to split from

\item[{\sphinxstylestrong{Returns}}] \leavevmode
\item[{\sphinxstylestrong{——\sphinxhyphen{}}}] \leavevmode
df\_train, df\_test

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{extrapolate\_timestamps() (in module src.preprocess.preprocess)@\spxentry{extrapolate\_timestamps()}\spxextra{in module src.preprocess.preprocess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/preprocess/preprocess/index:src.preprocess.preprocess.extrapolate_timestamps}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.preprocess.preprocess.}}\sphinxbfcode{\sphinxupquote{extrapolate\_timestamps}}}{\emph{\DUrole{n}{df}}, \emph{\DUrole{n}{horizon}\DUrole{o}{=}\DUrole{default_value}{dt.timedelta(weeks=26)}}}{}
Extrapolate the data with timestamps for the future.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.DataFrame}}{]}
data to extrapolate.

\item[{\sphinxstylestrong{horizon}}] \leavevmode{[}\sphinxcode{\sphinxupquote{dt.timedelta}}{]}
the amount of time to extrapolate further.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
Only the extrapolated/added part.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.preprocess.update\_extremes}}}
\label{\detokenize{autoapi/src/preprocess/update_extremes/index:module-src.preprocess.update_extremes}}\label{\detokenize{autoapi/src/preprocess/update_extremes/index:src-preprocess-update-extremes}}\label{\detokenize{autoapi/src/preprocess/update_extremes/index::doc}}\index{module@\spxentry{module}!src.preprocess.update\_extremes@\spxentry{src.preprocess.update\_extremes}}\index{src.preprocess.update\_extremes@\spxentry{src.preprocess.update\_extremes}!module@\spxentry{module}}

\subsubsection{\sphinxstyleliteralintitle{\sphinxupquote{src.utils}}}
\label{\detokenize{autoapi/src/utils/index:module-src.utils}}\label{\detokenize{autoapi/src/utils/index:src-utils}}\label{\detokenize{autoapi/src/utils/index::doc}}\index{module@\spxentry{module}!src.utils@\spxentry{src.utils}}\index{src.utils@\spxentry{src.utils}!module@\spxentry{module}}

\paragraph{Submodules}
\label{\detokenize{autoapi/src/utils/index:submodules}}

\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.utils.logger}}}
\label{\detokenize{autoapi/src/utils/logger/index:module-src.utils.logger}}\label{\detokenize{autoapi/src/utils/logger/index:src-utils-logger}}\label{\detokenize{autoapi/src/utils/logger/index::doc}}\index{module@\spxentry{module}!src.utils.logger@\spxentry{src.utils.logger}}\index{src.utils.logger@\spxentry{src.utils.logger}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/utils/logger/index:module-contents}}\index{init\_logging() (in module src.utils.logger)@\spxentry{init\_logging()}\spxextra{in module src.utils.logger}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/logger/index:src.utils.logger.init_logging}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.logger.}}\sphinxbfcode{\sphinxupquote{init\_logging}}}{}{}
Initialize logger.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{logger}} \sphinxhref{https://docs.python.org/3/library/functions.html\#object}{\sphinxcode{\sphinxupquote{object}}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.utils.parser}}}
\label{\detokenize{autoapi/src/utils/parser/index:module-src.utils.parser}}\label{\detokenize{autoapi/src/utils/parser/index:src-utils-parser}}\label{\detokenize{autoapi/src/utils/parser/index::doc}}\index{module@\spxentry{module}!src.utils.parser@\spxentry{src.utils.parser}}\index{src.utils.parser@\spxentry{src.utils.parser}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/utils/parser/index:module-contents}}\index{parse\_config() (in module src.utils.parser)@\spxentry{parse\_config()}\spxextra{in module src.utils.parser}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/parser/index:src.utils.parser.parse_config}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.parser.}}\sphinxbfcode{\sphinxupquote{parse\_config}}}{\emph{\DUrole{n}{abs\_path}}}{{ $\rightarrow$ EnvYAML}}
Parse the configuration in EnvYAML format.

\end{fulllineitems}

\index{parse\_args() (in module src.utils.parser)@\spxentry{parse\_args()}\spxextra{in module src.utils.parser}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/parser/index:src.utils.parser.parse_args}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.parser.}}\sphinxbfcode{\sphinxupquote{parse\_args}}}{}{{ $\rightarrow$ \sphinxhref{https://docs.python.org/3/library/stdtypes.html\#dict}{dict}}}
Parse the command\sphinxhyphen{}line arguments.

\end{fulllineitems}



\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.utils.preprocess}}}
\label{\detokenize{autoapi/src/utils/preprocess/index:module-src.utils.preprocess}}\label{\detokenize{autoapi/src/utils/preprocess/index:src-utils-preprocess}}\label{\detokenize{autoapi/src/utils/preprocess/index::doc}}\index{module@\spxentry{module}!src.utils.preprocess@\spxentry{src.utils.preprocess}}\index{src.utils.preprocess@\spxentry{src.utils.preprocess}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/utils/preprocess/index:module-contents}}\index{downcast() (in module src.utils.preprocess)@\spxentry{downcast()}\spxextra{in module src.utils.preprocess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/preprocess/index:src.utils.preprocess.downcast}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.preprocess.}}\sphinxbfcode{\sphinxupquote{downcast}}}{\emph{\DUrole{n}{s}}, \emph{\DUrole{n}{try\_numeric}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{category}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Downcast  a series to the lowest possible memory type.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{s}}] \leavevmode{[}\sphinxcode{\sphinxupquote{pd.Series}}{]}
Series to downcast.

\item[{\sphinxstylestrong{try\_numeric: bool}}] \leavevmode
If True it will try to read strings as numeric values.

\item[{\sphinxstylestrong{category: bool}}] \leavevmode
If True (string) objects will be cast as a category.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{Downcasted}} series.}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{map\_labels() (in module src.utils.preprocess)@\spxentry{map\_labels()}\spxextra{in module src.utils.preprocess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/preprocess/index:src.utils.preprocess.map_labels}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.preprocess.}}\sphinxbfcode{\sphinxupquote{map\_labels}}}{\emph{\DUrole{n}{series}}, \emph{\DUrole{n}{kind}\DUrole{o}{=}\DUrole{default_value}{'categorical'}}, \emph{\DUrole{n}{labels}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{backwards}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{o}{**}\DUrole{n}{arg}}}{}
Map a Series values by the labels given.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{series: pd.Series}}] \leavevmode
Series to map on.

\item[{\sphinxstylestrong{kind: str}}] \leavevmode
Indicator for kind of preprocess in series. With kind of \{“categorical”, “ordinal”\}  the mapping is applied,
otherwise not.

\item[{\sphinxstylestrong{labels: dict}}] \leavevmode
Defines with the mapping \{key\_0: value\_0, etc.\}.

\item[{\sphinxstylestrong{arg:}}] \leavevmode
Additional arguments.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.Series}}}] \leavevmode
Series with mapped values.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{MinMaxScaler (class in src.utils.preprocess)@\spxentry{MinMaxScaler}\spxextra{class in src.utils.preprocess}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/preprocess/index:src.utils.preprocess.MinMaxScaler}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{src.utils.preprocess.}}\sphinxbfcode{\sphinxupquote{MinMaxScaler}}}{\emph{\DUrole{n}{upper}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{lower}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{} 1}}}{}
MinMax Scaler like in sklearn, prevents total library import/dependency.

Initialize scaler with upper and lower boundary.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{upper}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/functions.html\#float}{\sphinxcode{\sphinxupquote{float}}}{]}
upper boundary to scale to

\item[{\sphinxstylestrong{lower}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/functions.html\#float}{\sphinxcode{\sphinxupquote{float}}}{]}
lower boundary to scale to

\end{description}

\end{description}\end{quote}
\index{fit() (src.utils.preprocess.MinMaxScaler method)@\spxentry{fit()}\spxextra{src.utils.preprocess.MinMaxScaler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/preprocess/index:src.utils.preprocess.MinMaxScaler.fit}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{fit}}}{\emph{\DUrole{n}{self}}, \emph{\DUrole{n}{X}}, \emph{\DUrole{n}{y}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Get fit parameters.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{X}}] \leavevmode{[}\sphinxcode{\sphinxupquote{np.array}}{]}
preprocess to fit on

\item[{\sphinxstylestrong{y}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/constants.html\#None}{\sphinxcode{\sphinxupquote{None}}}{]}
solely for consistency

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{self}}}] \leavevmode
instance with self.min, self.max defined.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{transform() (src.utils.preprocess.MinMaxScaler method)@\spxentry{transform()}\spxextra{src.utils.preprocess.MinMaxScaler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/preprocess/index:src.utils.preprocess.MinMaxScaler.transform}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{transform}}}{\emph{\DUrole{n}{self}}, \emph{\DUrole{n}{X}}}{}
Scales preprocess according to fitted parameters.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{X}}] \leavevmode{[}\sphinxcode{\sphinxupquote{np.array}}{]}
preprocess to scale

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{np.array}}}] \leavevmode
scaled preprocess

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{fit\_transform() (src.utils.preprocess.MinMaxScaler method)@\spxentry{fit\_transform()}\spxextra{src.utils.preprocess.MinMaxScaler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/preprocess/index:src.utils.preprocess.MinMaxScaler.fit_transform}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{fit\_transform}}}{\emph{\DUrole{n}{self}}, \emph{\DUrole{n}{X}}, \emph{\DUrole{n}{y}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Execute consecutively self.fit and self.transform.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{X}}] \leavevmode{[}\sphinxcode{\sphinxupquote{np.array}}{]}
preprocess to scale

\item[{\sphinxstylestrong{y}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/constants.html\#None}{\sphinxcode{\sphinxupquote{None}}}{]}
solely for consistency

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{np.array}}}] \leavevmode
scaled preprocess

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{inverse\_transform() (src.utils.preprocess.MinMaxScaler method)@\spxentry{inverse\_transform()}\spxextra{src.utils.preprocess.MinMaxScaler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/preprocess/index:src.utils.preprocess.MinMaxScaler.inverse_transform}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{inverse\_transform}}}{\emph{\DUrole{n}{self}}, \emph{\DUrole{n}{X}}, \emph{\DUrole{n}{y}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Scale back to original domain.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{X}}] \leavevmode{[}\sphinxcode{\sphinxupquote{np.array}}{]}
preprocess to scale

\item[{\sphinxstylestrong{y}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/constants.html\#None}{\sphinxcode{\sphinxupquote{None}}}{]}
solely for consistency

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{np.array}}}] \leavevmode
scaled preprocess

\end{description}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.utils.snowflake}}}
\label{\detokenize{autoapi/src/utils/snowflake/index:module-src.utils.snowflake}}\label{\detokenize{autoapi/src/utils/snowflake/index:src-utils-snowflake}}\label{\detokenize{autoapi/src/utils/snowflake/index::doc}}\index{module@\spxentry{module}!src.utils.snowflake@\spxentry{src.utils.snowflake}}\index{src.utils.snowflake@\spxentry{src.utils.snowflake}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/utils/snowflake/index:module-contents}}\index{logger (in module src.utils.snowflake)@\spxentry{logger}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.logger}}\pysigline{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{logger}}}
\end{fulllineitems}

\index{config (in module src.utils.snowflake)@\spxentry{config}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.config}}\pysigline{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{config}}}
\end{fulllineitems}

\index{channel\_like (in module src.utils.snowflake)@\spxentry{channel\_like}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.channel_like}}\pysigline{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{channel\_like}}\sphinxbfcode{\sphinxupquote{ = register://electricity/0/activepower/\%?avg=15}}}
\end{fulllineitems}

\index{column\_details (in module src.utils.snowflake)@\spxentry{column\_details}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.column_details}}\pysigline{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{column\_details}}\sphinxbfcode{\sphinxupquote{ =}}}
\end{fulllineitems}


(BOXID VARCHAR(50), L VARCHAR(5),
YEAR NUMBER(4), WEEK NUMBER(2),
PROCESSED\_ON TIMESTAMP\_TZ,
MAX DOUBLE, MIN DOUBLE)
\index{format\_connection() (in module src.utils.snowflake)@\spxentry{format\_connection()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.format_connection}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{format\_connection}}}{\emph{\DUrole{n}{name}}}{}
Get (connection) details in the right format for different tables.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{name}}] \leavevmode{[}\sphinxcode{\sphinxupquote{name}} \sphinxcode{\sphinxupquote{of}} \sphinxcode{\sphinxupquote{the}} \sphinxcode{\sphinxupquote{different}} \sphinxcode{\sphinxupquote{sources}}{]}
\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{Connection}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_meta() (in module src.utils.snowflake)@\spxentry{read\_meta()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.read_meta}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{read\_meta}}}{\emph{\DUrole{n}{boxid}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Read meta preprocess of DALI box.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{boxid}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#list}{\sphinxcode{\sphinxupquote{list}}}{]}
ID of DALI box to read.
None results in all available preprocess of DALI boxes that have nominal power specified.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}} \sphinxcode{\sphinxupquote{with}} metadata.}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{make\_week\_extremes\_query() (in module src.utils.snowflake)@\spxentry{make\_week\_extremes\_query()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.make_week_extremes_query}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{make\_week\_extremes\_query}}}{\emph{\DUrole{n}{boxid}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{last\_processed}\DUrole{o}{=}\DUrole{default_value}{dt.datetime(2001, 1, 1)}}}{}
Build the query to request week extremes.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{boxid}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#list}{\sphinxcode{\sphinxupquote{list}}}{]}
If not None: select specific boxes.

\item[{\sphinxstylestrong{last\_processed: datetime}}] \leavevmode
Date to determine week extremes from. Cuts are always made on the last monday.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#str}{\sphinxcode{\sphinxupquote{str}}}}] \leavevmode
Query string.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_table\_query() (in module src.utils.snowflake)@\spxentry{create\_table\_query()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.create_table_query}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{create\_table\_query}}}{\emph{\DUrole{n}{query}}}{}
Make query to create or replace table and insert preprocess of select query.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{query}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#str}{\sphinxcode{\sphinxupquote{str}}}{]}
Select query to be used.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#str}{\sphinxcode{\sphinxupquote{str}}}}] \leavevmode
New query

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{insert\_table\_query() (in module src.utils.snowflake)@\spxentry{insert\_table\_query()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.insert_table_query}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{insert\_table\_query}}}{\emph{\DUrole{n}{query}}}{}
Make query to insert preprocess of select query in an existing table.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{query}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#str}{\sphinxcode{\sphinxupquote{str}}}{]}
Select query to be used.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#str}{\sphinxcode{\sphinxupquote{str}}}}] \leavevmode
New query

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_week\_extremes() (in module src.utils.snowflake)@\spxentry{create\_week\_extremes()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.create_week_extremes}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{create\_week\_extremes}}}{}{}
Execute query to create whole new table of week extremes asynchroniously.

\end{fulllineitems}

\index{get\_last\_processed\_time() (in module src.utils.snowflake)@\spxentry{get\_last\_processed\_time()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.get_last_processed_time}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{get\_last\_processed\_time}}}{}{}
Retrieve last time table update has been done.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/datetime.html\#module-datetime}{\sphinxcode{\sphinxupquote{datetime}}}}] \leavevmode
Last processing time.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{update\_week\_extremes() (in module src.utils.snowflake)@\spxentry{update\_week\_extremes()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.update_week_extremes}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{update\_week\_extremes}}}{}{}
Update week extremes from last processing time upt o last monday.

\end{fulllineitems}

\index{read\_week\_extremes() (in module src.utils.snowflake)@\spxentry{read\_week\_extremes()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.read_week_extremes}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{read\_week\_extremes}}}{\emph{\DUrole{n}{boxid}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{L}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Read week extremes for a DALI box and phase.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{boxid: list}}] \leavevmode
If not None: A list with DALI box IDs to read.

\item[{\sphinxstylestrong{L: str}}] \leavevmode
The phases to retrieve (sumli, L1, L2, L3)

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
Week extremes.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{clear\_forecasts() (in module src.utils.snowflake)@\spxentry{clear\_forecasts()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.clear_forecasts}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{clear\_forecasts}}}{}{}
Clear the table with forecasts.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/constants.html\#None}{\sphinxcode{\sphinxupquote{None}}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{clear\_forecast\_meta() (in module src.utils.snowflake)@\spxentry{clear\_forecast\_meta()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.clear_forecast_meta}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{clear\_forecast\_meta}}}{}{}
Clear the table with forecast metadata.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/constants.html\#None}{\sphinxcode{\sphinxupquote{None}}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{write\_forecasts() (in module src.utils.snowflake)@\spxentry{write\_forecasts()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.write_forecasts}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{write\_forecasts}}}{\emph{\DUrole{n}{df}}}{}
Write results into the Snowflake database.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df: pd.DataFrame}}] \leavevmode
Results to write.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/constants.html\#None}{\sphinxcode{\sphinxupquote{None}}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{write\_forecast\_meta() (in module src.utils.snowflake)@\spxentry{write\_forecast\_meta()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.write_forecast_meta}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{write\_forecast\_meta}}}{\emph{\DUrole{n}{df}}}{}
Write assessment of forecast on capacity to forecast metadata table in Snowflake.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{df: pd.DataFrame}}] \leavevmode
Assessment results.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/constants.html\#None}{\sphinxcode{\sphinxupquote{None}}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_forecasts() (in module src.utils.snowflake)@\spxentry{read\_forecasts()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.read_forecasts}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{read\_forecasts}}}{\emph{\DUrole{n}{boxid}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Read forecasts for Snowflake database.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{boxid: str}}] \leavevmode
Boxid of a DALI box. If not provided or None, all forecast are loaded.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
DataFrame with forecasts.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_forecast\_meta() (in module src.utils.snowflake)@\spxentry{read\_forecast\_meta()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.read_forecast_meta}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{read\_forecast\_meta}}}{}{}
Read assessment of forecasts.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
Results of he assessment of all DALI box forecasts.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_forecasted\_boxids() (in module src.utils.snowflake)@\spxentry{get\_forecasted\_boxids()}\spxextra{in module src.utils.snowflake}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/snowflake/index:src.utils.snowflake.get_forecasted_boxids}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.snowflake.}}\sphinxbfcode{\sphinxupquote{get\_forecasted\_boxids}}}{}{}
Get the boxids for boxes that are already forecasted.

(Should be adapted when multiple forecasts (done on different dates) are present in database).
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{pd.DataFrame}}}] \leavevmode
Unique boxids.

\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\subparagraph{\sphinxstyleliteralintitle{\sphinxupquote{src.utils.vault}}}
\label{\detokenize{autoapi/src/utils/vault/index:module-src.utils.vault}}\label{\detokenize{autoapi/src/utils/vault/index:src-utils-vault}}\label{\detokenize{autoapi/src/utils/vault/index::doc}}\index{module@\spxentry{module}!src.utils.vault@\spxentry{src.utils.vault}}\index{src.utils.vault@\spxentry{src.utils.vault}!module@\spxentry{module}}

\subparagraph{Module Contents}
\label{\detokenize{autoapi/src/utils/vault/index:module-contents}}\index{get\_secrets() (in module src.utils.vault)@\spxentry{get\_secrets()}\spxextra{in module src.utils.vault}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/vault/index:src.utils.vault.get_secrets}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.vault.}}\sphinxbfcode{\sphinxupquote{get\_secrets}}}{\emph{\DUrole{n}{connection}}}{}
Get secrets from Vault.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{connection: str}}] \leavevmode
The application/connection to get secrets for.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{requested}} \sphinxhref{https://docs.python.org/3/library/secrets.html\#module-secrets}{\sphinxcode{\sphinxupquote{secrets}}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_vault\_secret() (in module src.utils.vault)@\spxentry{get\_vault\_secret()}\spxextra{in module src.utils.vault}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/utils/vault/index:src.utils.vault.get_vault_secret}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.utils.vault.}}\sphinxbfcode{\sphinxupquote{get\_vault\_secret}}}{\emph{\DUrole{n}{url}}, \emph{\DUrole{n}{token}}, \emph{\DUrole{n}{path}}, \emph{\DUrole{n}{mount\_point}}, \emph{\DUrole{o}{**}\DUrole{n}{kwargs}}}{}
Get vault secrets to certain path in a dictionary.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{url}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#str}{\sphinxcode{\sphinxupquote{str}}}{]}
Base URL of Vault server

\item[{\sphinxstylestrong{token}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#str}{\sphinxcode{\sphinxupquote{str}}}{]}
Token to get access to Vault

\item[{\sphinxstylestrong{path}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#str}{\sphinxcode{\sphinxupquote{str}}}{]}
Relative path to location of secret

\item[{\sphinxstylestrong{mount\_point}}] \leavevmode{[}\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#str}{\sphinxcode{\sphinxupquote{str}}}{]}
Mount point of address

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#dict}{\sphinxcode{\sphinxupquote{dict}}}}] \leavevmode
Dictionary with keys and value of a secret

\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{Package Contents}
\label{\detokenize{autoapi/src/index:package-contents}}\index{init\_logging() (in module src)@\spxentry{init\_logging()}\spxextra{in module src}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{autoapi/src/index:src.init_logging}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{src.}}\sphinxbfcode{\sphinxupquote{init\_logging}}}{}{}
Initialize logger.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{logger}} \sphinxhref{https://docs.python.org/3/library/functions.html\#object}{\sphinxcode{\sphinxupquote{object}}}}] \leavevmode
\end{description}

\end{description}\end{quote}

\end{fulllineitems}



\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{s}
\item\relax\sphinxstyleindexentry{src}\sphinxstyleindexpageref{autoapi/src/index:\detokenize{module-src}}
\item\relax\sphinxstyleindexentry{src.forecast}\sphinxstyleindexpageref{autoapi/src/forecast/index:\detokenize{module-src.forecast}}
\item\relax\sphinxstyleindexentry{src.forecast.assess}\sphinxstyleindexpageref{autoapi/src/forecast/assess/index:\detokenize{module-src.forecast.assess}}
\item\relax\sphinxstyleindexentry{src.forecast.forecast}\sphinxstyleindexpageref{autoapi/src/forecast/forecast/index:\detokenize{module-src.forecast.forecast}}
\item\relax\sphinxstyleindexentry{src.forecast.make\_forecasts}\sphinxstyleindexpageref{autoapi/src/forecast/make_forecasts/index:\detokenize{module-src.forecast.make_forecasts}}
\item\relax\sphinxstyleindexentry{src.model}\sphinxstyleindexpageref{autoapi/src/model/index:\detokenize{module-src.model}}
\item\relax\sphinxstyleindexentry{src.model.format}\sphinxstyleindexpageref{autoapi/src/model/format/index:\detokenize{module-src.model.format}}
\item\relax\sphinxstyleindexentry{src.model.model}\sphinxstyleindexpageref{autoapi/src/model/model/index:\detokenize{module-src.model.model}}
\item\relax\sphinxstyleindexentry{src.plot}\sphinxstyleindexpageref{autoapi/src/plot/index:\detokenize{module-src.plot}}
\item\relax\sphinxstyleindexentry{src.plot.altair}\sphinxstyleindexpageref{autoapi/src/plot/altair/index:\detokenize{module-src.plot.altair}}
\item\relax\sphinxstyleindexentry{src.plot.dashboard}\sphinxstyleindexpageref{autoapi/src/plot/dashboard/index:\detokenize{module-src.plot.dashboard}}
\item\relax\sphinxstyleindexentry{src.plot.format}\sphinxstyleindexpageref{autoapi/src/plot/format/index:\detokenize{module-src.plot.format}}
\item\relax\sphinxstyleindexentry{src.preprocess}\sphinxstyleindexpageref{autoapi/src/preprocess/index:\detokenize{module-src.preprocess}}
\item\relax\sphinxstyleindexentry{src.preprocess.preprocess}\sphinxstyleindexpageref{autoapi/src/preprocess/preprocess/index:\detokenize{module-src.preprocess.preprocess}}
\item\relax\sphinxstyleindexentry{src.preprocess.update\_extremes}\sphinxstyleindexpageref{autoapi/src/preprocess/update_extremes/index:\detokenize{module-src.preprocess.update_extremes}}
\item\relax\sphinxstyleindexentry{src.utils}\sphinxstyleindexpageref{autoapi/src/utils/index:\detokenize{module-src.utils}}
\item\relax\sphinxstyleindexentry{src.utils.logger}\sphinxstyleindexpageref{autoapi/src/utils/logger/index:\detokenize{module-src.utils.logger}}
\item\relax\sphinxstyleindexentry{src.utils.parser}\sphinxstyleindexpageref{autoapi/src/utils/parser/index:\detokenize{module-src.utils.parser}}
\item\relax\sphinxstyleindexentry{src.utils.preprocess}\sphinxstyleindexpageref{autoapi/src/utils/preprocess/index:\detokenize{module-src.utils.preprocess}}
\item\relax\sphinxstyleindexentry{src.utils.snowflake}\sphinxstyleindexpageref{autoapi/src/utils/snowflake/index:\detokenize{module-src.utils.snowflake}}
\item\relax\sphinxstyleindexentry{src.utils.vault}\sphinxstyleindexpageref{autoapi/src/utils/vault/index:\detokenize{module-src.utils.vault}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}