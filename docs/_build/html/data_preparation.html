

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Data Preparation &#8212; `Spark project` 0.0.1 documentation</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modeling" href="modeling.html" />
    <link rel="prev" title="Data Understanding" href="data_understanding.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="general.html">General</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="business_understanding.html">Business Understanding</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="data_understanding.html">Data Understanding</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="">Data Preparation</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="modeling.html">Modeling</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="evaluation.html">Evaluation</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="deployment.html">Deployment</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="autoapi/index.html">API Reference</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar">

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>


<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

  <div class="bd-toc-item active">
  

  <ul class="nav bd-sidenav">
      
      
      
      
      
      
      
      
        
      
      
      
      
      
      
      
      
      
      
    </ul>

</nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#data-selection" class="nav-link">Data Selection</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#data-cleaning" class="nav-link">Data Cleaning</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#data-construction" class="nav-link">Data Construction</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#data-integration" class="nav-link">Data Integration</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#data-formatting" class="nav-link">Data Formatting</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#data-updating-process" class="nav-link">Data Updating Process</a>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="data-preparation">
<h1>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">¶</a></h1>
<p>The data preparation step focuses on converting raw measurement data with a frequency of 15 minutes into weekly extremes and preparing these extremes to be usable input for the forecasting model.</p>
<p>Initially the entire history is aggregated and stored in a Snowflake database. Consecutively, updates are done every week.</p>
<a class="reference internal image-reference" href="_images/process_data_preparation.png"><img alt="_images/process_data_preparation.png" class="align-center" src="_images/process_data_preparation.png" style="height: 250px;" /></a>
<p>The data preparation step resulting in weekly aggregated data.</p>
<section id="data-selection">
<h2>Data Selection<a class="headerlink" href="#data-selection" title="Permalink to this headline">¶</a></h2>
<p>Columns described in <span class="xref std std-ref">Data Understanding</span> are selected from the measurement data and metadata tables.</p>
<p>From the measurement data only data is selected from DALI boxes that have nominal power registered in the metadata table and that are in operation (<a class="reference internal" href="autoapi/src/utils/snowflake/index.html#src.utils.snowflake.read_meta" title="src.utils.snowflake.read_meta"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.utils.snowflake.read_meta()</span></code></a>). Both data and metadata are needed to indicate future overloading and add value to Grid Planners.</p>
<p>As mentioned only the active power (P) on medium voltage side is used initially. Apparent power (S) is preferred (for a more fair comparison with the nominal power), but since this is 15 minute average data, this is hard to reconstruct.</p>
<p>In this step the separate power phases are selected and processed as well as the sum of the phases (<a class="reference internal" href="autoapi/src/utils/snowflake/index.html#src.utils.snowflake.make_week_extremes_query" title="src.utils.snowflake.make_week_extremes_query"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.utils.snowflake.make_week_extremes_query()</span></code></a>).</p>
<p>Only the 15 minute average channels are selected for preprocessing.</p>
</section>
<section id="data-cleaning">
<h2>Data Cleaning<a class="headerlink" href="#data-cleaning" title="Permalink to this headline">¶</a></h2>
<p>No data cleaning is performed on the raw data before aggregation, but data is checked and cleaned on the following after loading (<a class="reference internal" href="autoapi/src/preprocess/preprocess/index.html#src.preprocess.preprocess.load_data" title="src.preprocess.preprocess.load_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.preprocess.preprocess.load_data()</span></code></a>) and before being used by a model for forecasting:</p>
<ul class="simple">
<li><p>Data of extremes (minimum or maximum) having the value of zero in the beginning of the series are removed (<a class="reference internal" href="autoapi/src/preprocess/preprocess/index.html#src.preprocess.preprocess.remove_leading_idling" title="src.preprocess.preprocess.remove_leading_idling"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.preprocess.preprocess.remove_leading_idling()</span></code></a>). This is for example the case if a DALI box is in operation, but its transformer is not.</p></li>
<li><p>Only data is used that has a history of more than two years (<a class="reference internal" href="autoapi/src/preprocess/preprocess/index.html#src.preprocess.preprocess.too_short" title="src.preprocess.preprocess.too_short"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.preprocess.preprocess.too_short()</span></code></a>). This will ensure in this stage that the seasonality (sub)model has enough data to tune on.</p></li>
<li><p>Only data is used of transformers that have a measurement in their history with an absolute value higher than half the transformer capacity (<a class="reference internal" href="autoapi/src/preprocess/preprocess/index.html#src.preprocess.preprocess.too_small" title="src.preprocess.preprocess.too_small"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.preprocess.preprocess.too_small()</span></code></a>).</p></li>
</ul>
<p>Duplicate data (can only be created by updating the extreme table) is not an issue for the model and will not be eliminated.</p>
<p>Missing data is neither a problem for the model and is also not imputed.</p>
</section>
<section id="data-construction">
<h2>Data Construction<a class="headerlink" href="#data-construction" title="Permalink to this headline">¶</a></h2>
<p>From the raw 15-minute data the weekly minimum and maximum are determined. This is done per channel and boxid (<a class="reference internal" href="autoapi/src/utils/snowflake/index.html#src.utils.snowflake.make_week_extremes_query" title="src.utils.snowflake.make_week_extremes_query"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.utils.snowflake.make_week_extremes_query()</span></code></a>).
The week definition used is the ISO-week since this is always a full week.</p>
<p>A SQL query aggregates and writes the result asynchronously on the Snowflake database. This can be done in batch for all historic measurements (<a class="reference internal" href="autoapi/src/utils/snowflake/index.html#src.utils.snowflake.create_week_extremes" title="src.utils.snowflake.create_week_extremes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.utils.snowflake.create_week_extremes()</span></code></a>), but the created table can also be updated per week (<a class="reference internal" href="autoapi/src/utils/snowflake/index.html#src.utils.snowflake.update_week_extremes" title="src.utils.snowflake.update_week_extremes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.utils.snowflake.update_week_extremes()</span></code></a>).</p>
<table class="colwidths-given table" id="id1">
<caption><span class="caption-text">Snowflake table details for weekly extremes data.</span><a class="headerlink" href="#id1" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Database</p></td>
<td><p>DB_DATASCIENCE_P</p></td>
</tr>
<tr class="row-even"><td><p>Schema</p></td>
<td><p>DATASCIENCE_1_ETL</p></td>
</tr>
<tr class="row-odd"><td><p>Table</p></td>
<td><p>DS_SPARK_DALI_WEEK_EXTREMES</p></td>
</tr>
</tbody>
</table>
<p>The fields of the table are listed below. The table is clustered by BOXID and L (phase).
The amount of rows is condensed from 89,052,020,404 to 3,457,856 records.</p>
<table class="colwidths-given table" id="id2">
<caption><span class="caption-text">Extremes table fields.</span><a class="headerlink" href="#id2" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Field</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>BOXID</p></td>
<td><p>VARCHAR</p></td>
<td><p>ESD.000240-2</p></td>
</tr>
<tr class="row-odd"><td><p>L</p></td>
<td><p>VARCHAR</p></td>
<td><p>sumli</p></td>
</tr>
<tr class="row-even"><td><p>YEAR</p></td>
<td><p>NUMBER</p></td>
<td><p>2021</p></td>
</tr>
<tr class="row-odd"><td><p>WEEK</p></td>
<td><p>NUMBER</p></td>
<td><p>53</p></td>
</tr>
<tr class="row-even"><td><p>PROCESSED_ON</p></td>
<td><p>TIMESTAMPTZ</p></td>
<td><p>2021-05-12 07:45:00.000000000</p></td>
</tr>
<tr class="row-odd"><td><p>MAX</p></td>
<td><p>DOUBLE</p></td>
<td><p>678.90</p></td>
</tr>
<tr class="row-even"><td><p>MIN</p></td>
<td><p>DOUBLE</p></td>
<td><p>123.45</p></td>
</tr>
</tbody>
</table>
</section>
<section id="data-integration">
<h2>Data Integration<a class="headerlink" href="#data-integration" title="Permalink to this headline">¶</a></h2>
<p>Since no additional data sources are used, no joins or merges are required.</p>
</section>
<section id="data-formatting">
<h2>Data Formatting<a class="headerlink" href="#data-formatting" title="Permalink to this headline">¶</a></h2>
<p>The model does not demand an order (e.g. by year and week) of the data.
For the modelling stage the data is queried from the table in <a class="reference internal" href="#data-construction">Data Construction</a></p>
<p>Consecutively, a date column is constructed from the ISO year and week format with day==1.</p>
<p>The extra columns period and model_var are assigned and filled with the values “history”, “observed” respectively for measurement data.
This is in preparation for long formatting and concatenating forecast results in a later stage (<a class="reference internal" href="autoapi/src/preprocess/preprocess/index.html#src.preprocess.preprocess.format_data" title="src.preprocess.preprocess.format_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.preprocess.preprocess.format_data()</span></code></a>).</p>
<p>An example of the loaded extreme data is shown below:</p>
<a class="reference internal image-reference" href="_images/loaded_extremes.png"><img alt="_images/loaded_extremes.png" class="align-center" src="_images/loaded_extremes.png" style="width: 800px;" /></a>
<p>The format of the loaded extremes data.</p>
</section>
<section id="data-updating-process">
<h2>Data Updating Process<a class="headerlink" href="#data-updating-process" title="Permalink to this headline">¶</a></h2>
<p>The weekly extremes can be updated on a weekly (or longer) basis.</p>
<p>By running <a class="reference internal" href="autoapi/src/preprocess/update_extremes/index.html#module-src.preprocess.update_extremes" title="src.preprocess.update_extremes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.preprocess.update_extremes()</span></code></a> the function <a class="reference internal" href="autoapi/src/utils/snowflake/index.html#src.utils.snowflake.update_week_extremes" title="src.utils.snowflake.update_week_extremes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">src.utils.snowflake.update_week_extremes()</span></code></a> is called.
This will will trigger the following steps which update the weekly extremes Snowflake table:</p>
<a class="reference internal image-reference" href="_images/preprocessing_details.png"><img alt="_images/preprocessing_details.png" class="align-center" src="_images/preprocessing_details.png" style="width: 400px;" /></a>
<p>The detailed process to create and assess load forecasts.</p>
</section>
</section>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="data_understanding.html" title="previous page">Data Understanding</a>
    <a class='right-next' id="next-link" href="modeling.html" title="next page">Modeling</a>

              </div>
              
          </main>
          

      </div>
    </div>

    <script src="_static/js/index.js"></script>
    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright Bram Vonk 2021.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>